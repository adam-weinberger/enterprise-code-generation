{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "import javalang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_line_indices(lines,num_label_lines=1,min_lines_above=1,min_lines_below=1):\n",
    "    \"\"\"\n",
    "    Takes lines of code and creates a list of line indices for lines that are not used for whitespace, comments, imports, or packages. \n",
    "    \"\"\"\n",
    "\n",
    "    # remove empty lines, single line comments, import statements, packages\n",
    "    relevant_lines_indices_with_mlcomments = [index for index, line in enumerate(lines) if line.strip() != '']\n",
    "    relevant_lines_indices_with_mlcomments = [index for index in relevant_lines_indices_with_mlcomments if not lines[index].strip().startswith('//')]\n",
    "    relevant_lines_indices_with_mlcomments = [index for index in relevant_lines_indices_with_mlcomments if not lines[index].strip().startswith('#')]\n",
    "    relevant_lines_indices_with_mlcomments = [index for index in relevant_lines_indices_with_mlcomments if not (lines[index].strip().startswith('import') or lines[index].strip().startswith('package'))]\n",
    "\n",
    "    # To handle multiline comments, we can use a flag\n",
    "    in_multiline_comment = False\n",
    "    relevant_line_indices = []\n",
    "\n",
    "    for index in relevant_lines_indices_with_mlcomments:\n",
    "        line = lines[index]\n",
    "\n",
    "        if line.strip().startswith('/*'):\n",
    "            in_multiline_comment = True\n",
    "\n",
    "        if not in_multiline_comment:\n",
    "            relevant_line_indices.append(index)\n",
    "\n",
    "        if line.strip().endswith('*/'):\n",
    "            in_multiline_comment = False\n",
    "    \n",
    "    trimmed_relevant_line_indices = relevant_line_indices[min_lines_above+1:- (num_label_lines + min_lines_below)]\n",
    "\n",
    "    return trimmed_relevant_line_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_token_indices(lines, num_label_tokens=1, min_tokens_before=1, min_tokens_after=1):\n",
    "    \"\"\"\n",
    "    Takes lines of code and creates a list of token indices for tokens that are not used for whitespace, comments, imports, or packages. \n",
    "    \"\"\"\n",
    "\n",
    "    code = \"\".join(lines)\n",
    "    tokens = list(javalang.tokenizer.tokenize(code))\n",
    "\n",
    "    # Get the indices of tokens that are not whitespace or comments.\n",
    "    relevant_token_indices_with_mlcomments = [index for index, token in enumerate(tokens) if token.value.strip() != '' and not ('Comment' in token.__class__.__name__)]\n",
    "\n",
    "    # Filter out 'import' and 'package' tokens.\n",
    "    relevant_token_indices = [index for index in relevant_token_indices_with_mlcomments if tokens[index].value not in ['import', 'package']]\n",
    "\n",
    "    # Trimming tokens\n",
    "    trimmed_relevant_token_indices = relevant_token_indices[min_tokens_before:- (num_label_tokens + min_tokens_after)]\n",
    "\n",
    "    return trimmed_relevant_token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(prefix_lines,suffix_lines,infill=True,max_lines_above=50,max_lines_below=50):\n",
    "    \"\"\"\n",
    "    Takes the prefix_lines and suffix_lines and uses them to consruct the prompt. Defines prompt style. Limits prompt size. \n",
    "    \"\"\"\n",
    "\n",
    "    # Limit the number of lines in the prefix and suffix to a maximum number of lines. \n",
    "    if len(prefix_lines) > max_lines_above:\n",
    "        prefix_lines = prefix_lines[-max_lines_above:]\n",
    "        \n",
    "    if len(suffix_lines) > max_lines_below:\n",
    "        suffix_lines = suffix_lines[:max_lines_below]\n",
    "\n",
    "    if infill == True:\n",
    "        prompt = f'<PRE> {\"\".join(prefix_lines)} <SUF>{\"\".join(suffix_lines)} <MID>'\n",
    "    else:\n",
    "        prompt = \"\".join(prefix_lines)\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_removal_prompts(lines,line_to_remove_index=None,num_label_lines=1,infill=True,max_lines_above=50,max_lines_below=50):\n",
    "    \"\"\"\n",
    "    Given lines of code, will remove either a single line or multiple lines in order to create an infill prompts\n",
    "    and return a (prompt, label, start index of label, end index of label) \n",
    "    \"\"\"\n",
    "    \n",
    "    if line_to_remove_index == None:\n",
    "        relevant_line_indices = get_relevant_line_indices(lines)\n",
    "        line_to_remove_index = random.choice(relevant_line_indices)\n",
    "\n",
    "    last_line_to_remove_index = line_to_remove_index + num_label_lines\n",
    "    label = \"\".join(lines[line_to_remove_index:last_line_to_remove_index])\n",
    "    prefix_lines = lines[:line_to_remove_index]\n",
    "    suffix_lines = lines[last_line_to_remove_index:]\n",
    "\n",
    "    prompt = create_prompt(prefix_lines, suffix_lines, infill=infill,  max_lines_above=max_lines_above, max_lines_below=max_lines_below)\n",
    "\n",
    "    return [prompt, label, line_to_remove_index + 1, last_line_to_remove_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_removal_prompts(lines,starting_token_index = None,num_label_tokens=1,infill=True,max_lines_above=50,max_lines_below=50):\n",
    "    \"\"\"\n",
    "    Given lines of code, will remove a random set of consecutive tokens to create an infill prompt. \n",
    "    \"\"\"\n",
    "\n",
    "    if starting_token_index == None:\n",
    "        relevant_token_indices = get_relevant_token_indices(lines,num_label_tokens=num_label_tokens)\n",
    "        starting_token_index = random.choice(relevant_token_indices)\n",
    "    \n",
    "    code = \"\".join(lines)\n",
    "    tokens = list(javalang.tokenizer.tokenize(code))\n",
    "\n",
    "    start_position = tokens[starting_token_index].position[1] - 1  # this gets the column start of the token\n",
    "    end_position = tokens[starting_token_index + num_label_tokens - 1].position[1] - 1 + len(tokens[starting_token_index + num_label_tokens - 1].value)  # this gets the column end of the last token\n",
    "    start_line = tokens[starting_token_index].position[0]\n",
    "    end_line = tokens[starting_token_index + num_label_tokens - 1].position[0]\n",
    "    \n",
    "    # List of lines before start line and the piece of line before the label. \n",
    "    prefix_lines = lines[:tokens[starting_token_index].position[0] - 1] + [lines[tokens[starting_token_index].position[0] - 1][:start_position]]\n",
    "    # List of the piece of line after the label and lines after end line. \n",
    "    suffix_lines = [lines[tokens[starting_token_index + num_label_tokens - 1].position[0] - 1][end_position:]] + lines[tokens[starting_token_index + num_label_tokens - 1].position[0]:]\n",
    "\n",
    "    prompt = create_prompt(prefix_lines, suffix_lines, infill=infill,  max_lines_above=max_lines_above, max_lines_below=max_lines_below)\n",
    "\n",
    "    label = code[len(\"\".join(prefix_lines)):len(code)-len(\"\".join(suffix_lines))]\n",
    "    \n",
    "    return [prompt, label, start_line, end_line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_method_in_file(lines, method_name):\n",
    "    \"\"\"\n",
    "    Given a method name, return the first line and last line of that method declaration.\n",
    "    \"\"\"\n",
    "\n",
    "    code = \"\".join(lines)\n",
    "\n",
    "    tree = javalang.parse.parse(code)\n",
    "    for path, node in tree.filter(javalang.tree.MethodDeclaration):\n",
    "        if node.name == method_name:\n",
    "            start_line = node.position.line\n",
    "            post_prefix_content = \"\".join(lines[start_line-1:])\n",
    "            post_prefix_tokens = list(javalang.tokenizer.tokenize(post_prefix_content))\n",
    "            \n",
    "            stack = []\n",
    "            for token in post_prefix_tokens:\n",
    "                if token.value == '{':\n",
    "                    stack.append('{')\n",
    "                \n",
    "                elif token.value == '}':\n",
    "                    stack.pop()\n",
    "                    if not stack:\n",
    "                        end_line = start_line + token.position.line - 1\n",
    "                        break\n",
    "                    \n",
    "            return (start_line, end_line)\n",
    "    return (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_declaration_prompts(lines,method_names,infill=True,max_lines_above=50,max_lines_below=50):\n",
    "    \"\"\"\n",
    "    Given a list of method names, if that method exists in a file, will create a prompt for each corresponding method. \n",
    "    \"\"\"\n",
    "\n",
    "    prompts = []\n",
    "    for m in method_names:\n",
    "        start_line, end_line = find_method_in_file(lines, m)\n",
    "        if start_line == None and end_line == None:\n",
    "            continue\n",
    "\n",
    "        label = \"\".join(lines[start_line:end_line])\n",
    "        prefix_lines = lines[:start_line]\n",
    "        suffix_lines = lines[end_line:]\n",
    "\n",
    "        prompt = create_prompt(prefix_lines, suffix_lines, infill=infill,  max_lines_above=max_lines_above, max_lines_below=max_lines_below)\n",
    "        prompts.extend([prompt, label, start_line, end_line])\n",
    "    \n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompts_df(folder_path,num_label_lines,lines_prompts_count,num_label_tokens,tokens_prompts_count):\n",
    "    \"\"\"\n",
    "    Given a folder of java files, returns a dictionary with three dataframes corresponding to three different kinds of prompts. \n",
    "    \"\"\"\n",
    "\n",
    "    df3_list = []\n",
    "    all_relevant_line_indices = []\n",
    "    all_relevant_token_indices = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            these_relevant_lines = [(file_path,num) for num in get_relevant_line_indices(lines)]\n",
    "            all_relevant_line_indices.extend(these_relevant_lines)\n",
    "            these_relevant_tokens = [(file_path,num) for num in get_relevant_token_indices(lines)]\n",
    "            all_relevant_token_indices.extend(these_relevant_tokens)\n",
    "\n",
    "            df3_row = method_declaration_prompts(lines,['defineProperties','defineAdditionalProperties'])\n",
    "            if df3_row != []:\n",
    "                df3_list.append(df3_row)\n",
    "\n",
    "    line_indices_for_lines_prompt_making = random.sample(all_relevant_line_indices, lines_prompts_count)\n",
    "    token_indices_for_tokens_prompt_making = random.sample(all_relevant_token_indices, tokens_prompts_count)\n",
    "\n",
    "    df2_list = []\n",
    "    for path, token_index in token_indices_for_tokens_prompt_making:\n",
    "\n",
    "        with open(path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        df2_row = token_removal_prompts(lines,starting_token_index=token_index,num_label_tokens=num_label_tokens)\n",
    "        if df2_row != []:\n",
    "                df2_list.append(df2_row)\n",
    "    \n",
    "    df1_list = []\n",
    "    for path, line_index in line_indices_for_lines_prompt_making:\n",
    "\n",
    "        with open(path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        df1_row = line_removal_prompts(lines,line_to_remove_index=line_index,num_label_lines=num_label_lines)\n",
    "        if df1_row != []:\n",
    "                df1_list.append(df1_row)\n",
    "\n",
    "    df_dict = {'lines_df': pd.DataFrame(df1_list), 'tokens_df': pd.DataFrame(df2_list), 'methods_df': pd.DataFrame(df3_list)}\n",
    "    pd.set_option('max_colwidth', 500)\n",
    "\n",
    "    return df_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
