{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06bd792f",
   "metadata": {},
   "source": [
    "## Notebook to prototype response generation from models\n",
    "\n",
    "Sections:\n",
    "1 - Run inference against locally hosted refact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed09773",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install human_eval data\n",
    "!pip install human_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0594069",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## measure_humaneval_continue.py refactored to remove MPI\n",
    "Demonstration of accessing model endpoint via refact endpoint at http://127.0.0.1:8008/v1/completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ae9b46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import termcolor\n",
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from human_eval.data import write_jsonl, read_problems\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79096576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global constants\n",
    "#MODEL = \"smallcloudai/Refact-1_6B-fim\"\n",
    "# MODEL = \"Refact/1.6B\"\n",
    "# MODEL = \"codellama/7b/lora-20231026-161421\"\n",
    "MODEL = \"codellama/7b/lora-20231107-201630\"\n",
    "#MODEL = \"iter0070-testloss0.833\"\n",
    "\n",
    "\n",
    "TEMPERATURE = 0.2\n",
    "TOP_P = 0.95\n",
    "TIMES = 1\n",
    "MAX_TOKENS = 256\n",
    "INFERENCE_ENDPOINT = 'http://52.36.165.232:8008'\n",
    "\n",
    "metadata = {\n",
    "    'MODEL': MODEL,\n",
    "    'TEMPERATURE': TEMPERATURE,\n",
    "    'TOP_P': TOP_P,\n",
    "    'TIMES': TIMES,\n",
    "    'MAX_TOKENS': MAX_TOKENS\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b63c2bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def run_completion_call(src_txt):\n",
    "    res = requests.post(f\"{INFERENCE_ENDPOINT}/v1/completions\", json={\n",
    "        \"model\": MODEL,\n",
    "        \"max_tokens\": MAX_TOKENS,\n",
    "        \"stream\": False,\n",
    "        \"echo\": True,\n",
    "        \"top_p\": TOP_P,\n",
    "        \"temperature\": TEMPERATURE,\n",
    "        \"prompt\": src_txt,\n",
    "        \"stop\": [\"\\n\\n\\n\"],\n",
    "    })\n",
    "    res.raise_for_status()\n",
    "    j = res.json()\n",
    "    print(j)\n",
    "    return j[\"choices\"][0][\"text\"]\n",
    "\n",
    "\n",
    "def test_by_continuing(case):\n",
    "    orig = case[\"prompt\"].rstrip()\n",
    "    print_me = termcolor.colored(orig[:-1], \"yellow\")\n",
    "    print(print_me)\n",
    "    t = run_completion_call(orig)\n",
    "    uncut = t\n",
    "    lines = t.split(\"\\n\")\n",
    "    filtered = [x for x in lines if x.startswith(\" \") or x.strip() == \"\"]\n",
    "    t = \"\\n\".join(filtered)\n",
    "    #assert uncut.startswith(t)\n",
    "    print_response = termcolor.colored(t, \"green\") + \" \" + termcolor.colored(uncut[len(t):], attrs=[\"dark\"])\n",
    "    print(print_response)\n",
    "    case[\"completion\"] = t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d54774d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------  case=0 ----------------------------------------\n",
      "\u001b[33mfrom typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-x51b78K9ef4Z', 'object': 'text_completion', 'status': 'completed', 'created': 1701775295.8195434, 'uploaded': 1701775340.0031796, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    for i in range(len(numbers) - 1):\\n        for j in range(i + 1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False\\n\\n\\ndef has_close_elements_2(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for i in range(len(numbers)):\\n        for j in range(i + 1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False\\n\\n\\ndef has_close_elements_3(numbers: List[float'}]}\n",
      "\u001b[32m\n",
      "    for i in range(len(numbers) - 1):\n",
      "        for j in range(i + 1, len(numbers)):\n",
      "            if abs(numbers[i] - numbers[j]) < threshold:\n",
      "                return True\n",
      "    return False\n",
      "\n",
      "\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "    for i in range(len(numbers)):\n",
      "        for j in range(i + 1, len(numbers)):\n",
      "            if abs(numbers[i] - numbers[j]) < threshold:\n",
      "                return True\n",
      "    return False\n",
      "\n",
      "\u001b[0m \u001b[2m - numbers[j]) < threshold:\n",
      "                return True\n",
      "    return False\n",
      "\n",
      "\n",
      "def has_close_elements_3(numbers: List[float\u001b[0m\n",
      "----------------------------------------  case=1 ----------------------------------------\n",
      "\u001b[33mfrom typing import List\n",
      "\n",
      "\n",
      "def separate_paren_groups(paren_string: str) -> List[str]:\n",
      "    \"\"\" Input to this function is a string containing multiple groups of nested parentheses. Your goal is to\n",
      "    separate those group into separate strings and return the list of those.\n",
      "    Separate groups are balanced (each open brace is properly closed) and not nested within each other\n",
      "    Ignore any spaces in the input string.\n",
      "    >>> separate_paren_groups('( ) (( )) (( )( ))')\n",
      "    ['()', '(())', '(()())']\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-3CAifKsYqkKZ', 'object': 'text_completion', 'status': 'completed', 'created': 1701775340.062791, 'uploaded': 1701775383.6787694, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    # TODO: Your code here\\n    pass\\n\\n\\ndef main():\\n    print(separate_paren_groups(\\'( ) (( )) (( )( ))\\'))\\n\\n\\nif __name__ == \\'__main__\\':\\n    main()\\n\\n\\n\"\"\"\\nSTRETCH GOALS:\\n\\n1. Write a function that takes a string and returns a list of all the balanced groups of parentheses in the string.\\n    >>> balanced_paren_groups(\\'( ) (( )) (( )( ))\\')\\n    [\\'()\\', \\'(())\\', \\'(()())\\']\\n    >>> balanced_paren_groups(\\'( ) (( )) (( )( )) ((( )))\\')\\n    [\\'()\\', \\'(())\\', \\'(()())\\', \\'((()))\\']\\n    >>> balanced_paren_groups(\\'( ) (( )) (( )( )) ((( ))) (((( ))))\\')\\n    [\\'()\\', \\'(())\\', \\'(()())\\', \\'((()))\\', \\'(((())))\\']\\n\\n2. Write a function that takes a string and returns a list of all the balanced groups of parentheses in the string'}]}\n",
      "\u001b[32m\n",
      "    # TODO: Your code here\n",
      "    pass\n",
      "\n",
      "\n",
      "    print(separate_paren_groups('( ) (( )) (( )( ))'))\n",
      "\n",
      "\n",
      "    main()\n",
      "\n",
      "\n",
      "\n",
      "    >>> balanced_paren_groups('( ) (( )) (( )( ))')\n",
      "    ['()', '(())', '(()())']\n",
      "    >>> balanced_paren_groups('( ) (( )) (( )( )) ((( )))')\n",
      "    ['()', '(())', '(()())', '((()))']\n",
      "    >>> balanced_paren_groups('( ) (( )) (( )( )) ((( ))) (((( ))))')\n",
      "    ['()', '(())', '(()())', '((()))', '(((())))']\n",
      "\u001b[0m \u001b[2m )) ((( )))')\n",
      "    ['()', '(())', '(()())', '((()))']\n",
      "    >>> balanced_paren_groups('( ) (( )) (( )( )) ((( ))) (((( ))))')\n",
      "    ['()', '(())', '(()())', '((()))', '(((())))']\n",
      "\n",
      "2. Write a function that takes a string and returns a list of all the balanced groups of parentheses in the string\u001b[0m\n",
      "----------------------------------------  case=2 ----------------------------------------\n",
      "\u001b[33m\n",
      "\n",
      "def truncate_number(number: float) -> float:\n",
      "    \"\"\" Given a positive floating point number, it can be decomposed into\n",
      "    and integer part (largest integer smaller than given number) and decimals\n",
      "    (leftover part always smaller than 1).\n",
      "\n",
      "    Return the decimal part of the number.\n",
      "    >>> truncate_number(3.5)\n",
      "    0.5\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-StRqDp3l6LdN', 'object': 'text_completion', 'status': 'completed', 'created': 1701775383.7365136, 'uploaded': 1701775427.287635, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    return number - int(number)\\n\\n\\ndef truncate_number_to_n_decimals(number: float, n: int) -> float:\\n    \"\"\" Given a positive floating point number and an integer, it can be\\n    decomposed into an integer part (largest integer smaller than given number)\\n    and decimals (leftover part always smaller than 1).\\n\\n    Return the decimal part of the number, truncated to n decimals.\\n    >>> truncate_number_to_n_decimals(3.5, 2)\\n    0.5\\n    >>> truncate_number_to_n_decimals(3.5, 1)\\n    0.5\\n    >>> truncate_number_to_n_decimals(3.5, 0)\\n    0.0\\n    \"\"\"\\n    return round(number - int(number), n)\\n\\n\\ndef truncate_number_to_n_decimals_str(number: float, n: int) -> str:\\n    \"\"\" Given a positive floating point number and an integer, it can be\\n    decom'}]}\n",
      "\u001b[32m\n",
      "    return number - int(number)\n",
      "\n",
      "\n",
      "    \"\"\" Given a positive floating point number and an integer, it can be\n",
      "    decomposed into an integer part (largest integer smaller than given number)\n",
      "    and decimals (leftover part always smaller than 1).\n",
      "\n",
      "    Return the decimal part of the number, truncated to n decimals.\n",
      "    >>> truncate_number_to_n_decimals(3.5, 2)\n",
      "    0.5\n",
      "    >>> truncate_number_to_n_decimals(3.5, 1)\n",
      "    0.5\n",
      "    >>> truncate_number_to_n_decimals(3.5, 0)\n",
      "    0.0\n",
      "    \"\"\"\n",
      "    return round(number - int(number), n)\n",
      "\n",
      "\n",
      "    \"\"\" Given a positive floating point number and an integer, it can be\n",
      "    decom\u001b[0m \u001b[2mmber_to_n_decimals_str(number: float, n: int) -> str:\n",
      "    \"\"\" Given a positive floating point number and an integer, it can be\n",
      "    decom\u001b[0m\n",
      "----------------------------------------  case=3 ----------------------------------------\n",
      "\u001b[33mfrom typing import List\n",
      "\n",
      "\n",
      "def below_zero(operations: List[int]) -> bool:\n",
      "    \"\"\" You're given a list of deposit and withdrawal operations on a bank account that starts with\n",
      "    zero balance. Your task is to detect if at any point the balance of account fallls below zero, and\n",
      "    at that point function should return True. Otherwise it should return False.\n",
      "    >>> below_zero([1, 2, 3])\n",
      "    False\n",
      "    >>> below_zero([1, 2, -4, 5])\n",
      "    True\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-efB77eQ6JKZv', 'object': 'text_completion', 'status': 'completed', 'created': 1701775427.3502045, 'uploaded': 1701775470.9288461, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    balance = 0\\n    for operation in operations:\\n        balance += operation\\n        if balance < 0:\\n            return True\\n    return False\\n\\n\\nif __name__ == \\'__main__\\':\\n    import doctest\\n    doctest.testmod()\\n\\n\\ndef below_zero_2(operations: List[int]) -> bool:\\n    \"\"\" You\\'re given a list of deposit and withdrawal operations on a bank account that starts with\\n    zero balance. Your task is to detect if at any point the balance of account fallls below zero, and\\n    at that point function should return True. Otherwise it should return False.\\n    >>> below_zero_2([1, 2, 3])\\n    False\\n    >>> below_zero_2([1, 2, -4, 5])\\n    True\\n    \"\"\"\\n    balance = 0\\n    for operation in operations:\\n        balance += operation\\n        if balance < 0:\\n            return True\\n    return False\\n\\n\\nif __name__ == \\'__main__\\':\\n    import doctest\\n    doctest.testmod()\\n\\n'}]}\n",
      "\u001b[32m\n",
      "    balance = 0\n",
      "    for operation in operations:\n",
      "        balance += operation\n",
      "        if balance < 0:\n",
      "            return True\n",
      "    return False\n",
      "\n",
      "\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "\n",
      "\n",
      "    \"\"\" You're given a list of deposit and withdrawal operations on a bank account that starts with\n",
      "    zero balance. Your task is to detect if at any point the balance of account fallls below zero, and\n",
      "    at that point function should return True. Otherwise it should return False.\n",
      "    >>> below_zero_2([1, 2, 3])\n",
      "    False\n",
      "    >>> below_zero_2([1, 2, -4, 5])\n",
      "    True\n",
      "    \"\"\"\n",
      "    balance = 0\n",
      "    for operation in operations:\n",
      "        balance += operation\n",
      "        if balance < 0:\n",
      "            return True\n",
      "    return False\n",
      "\n",
      "\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "\n",
      "\u001b[0m \u001b[2m   return True\n",
      "    return False\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "\n",
      "\u001b[0m\n",
      "----------------------------------------  case=4 ----------------------------------------\n",
      "\u001b[33mfrom typing import List\n",
      "\n",
      "\n",
      "def mean_absolute_deviation(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers, calculate Mean Absolute Deviation\n",
      "    around the mean of this dataset.\n",
      "    Mean Absolute Deviation is the average absolute difference between each\n",
      "    element and a centerpoint (mean in this case):\n",
      "    MAD = average | x - x_mean |\n",
      "    >>> mean_absolute_deviation([1.0, 2.0, 3.0, 4.0])\n",
      "    1.0\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-hePUWtN2LJfu', 'object': 'text_completion', 'status': 'completed', 'created': 1701775470.9898782, 'uploaded': 1701775514.5188775, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    if len(numbers) == 0:\\n        return 0\\n    mean = sum(numbers) / len(numbers)\\n    return sum([abs(x - mean) for x in numbers]) / len(numbers)\\n\\n\\ndef median_absolute_deviation(numbers: List[float]) -> float:\\n    \"\"\" For a given list of input numbers, calculate Median Absolute Deviation\\n    around the median of this dataset.\\n    Median Absolute Deviation is the average absolute difference between each\\n    element and a centerpoint (median in this case):\\n    MAD = average | x - x_median |\\n    >>> median_absolute_deviation([1.0, 2.0, 3.0, 4.0])\\n    0.5\\n    \"\"\"\\n    if len(numbers) == 0:\\n        return 0\\n    median = median_of_list(numbers)\\n    return sum([abs(x - median) for x in numbers]) / len(numbers)\\n\\n\\ndef median_of_list(numbers: List[float]) -> float:\\n    \"\"\" For a given list of input numbers'}]}\n",
      "\u001b[32m\n",
      "    if len(numbers) == 0:\n",
      "        return 0\n",
      "    mean = sum(numbers) / len(numbers)\n",
      "    return sum([abs(x - mean) for x in numbers]) / len(numbers)\n",
      "\n",
      "\n",
      "    \"\"\" For a given list of input numbers, calculate Median Absolute Deviation\n",
      "    around the median of this dataset.\n",
      "    Median Absolute Deviation is the average absolute difference between each\n",
      "    element and a centerpoint (median in this case):\n",
      "    MAD = average | x - x_median |\n",
      "    >>> median_absolute_deviation([1.0, 2.0, 3.0, 4.0])\n",
      "    0.5\n",
      "    \"\"\"\n",
      "    if len(numbers) == 0:\n",
      "        return 0\n",
      "    median = median_of_list(numbers)\n",
      "    return sum([abs(x - median) for x in numbers]) / len(numbers)\n",
      "\n",
      "\n",
      "    \"\"\" For a given list of input numbers\u001b[0m \u001b[2ms]) / len(numbers)\n",
      "\n",
      "\n",
      "def median_of_list(numbers: List[float]) -> float:\n",
      "    \"\"\" For a given list of input numbers\u001b[0m\n",
      "----------------------------------------  case=5 ----------------------------------------\n",
      "\u001b[33mfrom typing import List\n",
      "\n",
      "\n",
      "def intersperse(numbers: List[int], delimeter: int) -> List[int]:\n",
      "    \"\"\" Insert a number 'delimeter' between every two consecutive elements of input list `numbers'\n",
      "    >>> intersperse([], 4)\n",
      "    []\n",
      "    >>> intersperse([1, 2, 3], 4)\n",
      "    [1, 4, 2, 4, 3]\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-PPLH9CWePncz', 'object': 'text_completion', 'status': 'completed', 'created': 1701775514.5795271, 'uploaded': 1701775558.4520652, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    if len(numbers) == 0:\\n        return []\\n    else:\\n        return [numbers[0]] + [delimeter] + intersperse(numbers[1:], delimeter)\\n\\n\\ndef intersperse_with_function(numbers: List[int], delimeter: int, f: callable) -> List[int]:\\n    \"\"\" Insert a number \\'delimeter\\' between every two consecutive elements of input list `numbers\\'\\n    >>> intersperse_with_function([], 4, lambda x: x)\\n    []\\n    >>> intersperse_with_function([1, 2, 3], 4, lambda x: x)\\n    [1, 4, 2, 4, 3]\\n    \"\"\"\\n    if len(numbers) == 0:\\n        return []\\n    else:\\n        return [f(numbers[0])] + [delimeter] + intersperse_with_function(numbers[1:], delimeter, f)\\n\\n\\ndef intersperse_with_function_and_argument(numbers: List[int], delimeter: int'}]}\n",
      "\u001b[32m\n",
      "    if len(numbers) == 0:\n",
      "        return []\n",
      "    else:\n",
      "        return [numbers[0]] + [delimeter] + intersperse(numbers[1:], delimeter)\n",
      "\n",
      "\n",
      "    \"\"\" Insert a number 'delimeter' between every two consecutive elements of input list `numbers'\n",
      "    >>> intersperse_with_function([], 4, lambda x: x)\n",
      "    []\n",
      "    >>> intersperse_with_function([1, 2, 3], 4, lambda x: x)\n",
      "    [1, 4, 2, 4, 3]\n",
      "    \"\"\"\n",
      "    if len(numbers) == 0:\n",
      "        return []\n",
      "    else:\n",
      "        return [f(numbers[0])] + [delimeter] + intersperse_with_function(numbers[1:], delimeter, f)\n",
      "\n",
      "\u001b[0m \u001b[2mreturn [f(numbers[0])] + [delimeter] + intersperse_with_function(numbers[1:], delimeter, f)\n",
      "\n",
      "\n",
      "def intersperse_with_function_and_argument(numbers: List[int], delimeter: int\u001b[0m\n",
      "----------------------------------------  case=6 ----------------------------------------\n",
      "\u001b[33mfrom typing import List\n",
      "\n",
      "\n",
      "def parse_nested_parens(paren_string: str) -> List[int]:\n",
      "    \"\"\" Input to this function is a string represented multiple groups for nested parentheses separated by spaces.\n",
      "    For each of the group, output the deepest level of nesting of parentheses.\n",
      "    E.g. (()()) has maximum two levels of nesting while ((())) has three.\n",
      "\n",
      "    >>> parse_nested_parens('(()()) ((())) () ((())()())')\n",
      "    [2, 3, 1, 3]\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-QeyVeGuxpD6x', 'object': 'text_completion', 'status': 'completed', 'created': 1701775558.50854, 'uploaded': 1701775602.2771006, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    # TODO: Write your code here\\n    return [0]\\n\\n\\nif __name__ == \\'__main__\\':\\n    import doctest\\n    doctest.testmod()\\n\\n    # These \"asserts\" are used for self-checking and not for an auto-testing\\n    assert parse_nested_parens(\\'(()()) ((())) () ((())()())\\') == [2, 3, 1, 3]\\n    assert parse_nested_parens(\\'()\\') == [0]\\n    assert parse_nested_parens(\\'((()))\\') == [2]\\n    assert parse_nested_parens(\\'((())) ()\\') == [2, 1]\\n    assert parse_nested_parens(\\'((())) () ()\\') == [2, 1, 0]\\n    assert parse_nested_parens(\\'((())) () () ()\\') == [2, 1, 0, 0]\\n    assert parse_nested_parens(\\'((())) () () () ()\\') == [2, 1, 0, 0, 0]\\n    assert parse_nested_parens(\\'((())) () () ()'}]}\n",
      "\u001b[32m\n",
      "    # TODO: Write your code here\n",
      "    return [0]\n",
      "\n",
      "\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "\n",
      "    # These \"asserts\" are used for self-checking and not for an auto-testing\n",
      "    assert parse_nested_parens('(()()) ((())) () ((())()())') == [2, 3, 1, 3]\n",
      "    assert parse_nested_parens('()') == [0]\n",
      "    assert parse_nested_parens('((()))') == [2]\n",
      "    assert parse_nested_parens('((())) ()') == [2, 1]\n",
      "    assert parse_nested_parens('((())) () ()') == [2, 1, 0]\n",
      "    assert parse_nested_parens('((())) () () ()') == [2, 1, 0, 0]\n",
      "    assert parse_nested_parens('((())) () () () ()') == [2, 1, 0, 0, 0]\n",
      "    assert parse_nested_parens('((())) () () ()\u001b[0m \u001b[2mted_parens('((())) () () ()\u001b[0m\n",
      "----------------------------------------  case=7 ----------------------------------------\n",
      "\u001b[33mfrom typing import List\n",
      "\n",
      "\n",
      "def filter_by_substring(strings: List[str], substring: str) -> List[str]:\n",
      "    \"\"\" Filter an input list of strings only for ones that contain given substring\n",
      "    >>> filter_by_substring([], 'a')\n",
      "    []\n",
      "    >>> filter_by_substring(['abc', 'bacd', 'cde', 'array'], 'a')\n",
      "    ['abc', 'bacd', 'array']\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-YHNqgtU8JTYs', 'object': 'text_completion', 'status': 'completed', 'created': 1701775602.3437557, 'uploaded': 1701775646.5788019, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    return [s for s in strings if substring in s]\\n\\n\\ndef filter_by_substring_regex(strings: List[str], substring: str) -> List[str]:\\n    \"\"\" Filter an input list of strings only for ones that contain given substring\\n    >>> filter_by_substring_regex([], \\'a\\')\\n    []\\n    >>> filter_by_substring_regex([\\'abc\\', \\'bacd\\', \\'cde\\', \\'array\\'], \\'a\\')\\n    [\\'abc\\', \\'bacd\\', \\'array\\']\\n    \"\"\"\\n    return [s for s in strings if substring in s]\\n\\n\\ndef filter_by_substring_regex_compiled(strings: List[str], substring: str) -> List[str]:\\n    \"\"\" Filter an input list of strings only for ones that contain given substring\\n    >>> filter_by_substring_regex_compiled([], \\'a\\')\\n    []\\n    >>> filter_by_substring_regex_compiled([\\'abc\\', \\'bacd\\', \\'cde\\', \\'array\\'], \\'a\\')\\n    [\\'abc\\', \\'bacd\\', \\'array\\']\\n    \"\"\"\\n    return [s for s in'}]}\n",
      "\u001b[32m\n",
      "    return [s for s in strings if substring in s]\n",
      "\n",
      "\n",
      "    \"\"\" Filter an input list of strings only for ones that contain given substring\n",
      "    >>> filter_by_substring_regex([], 'a')\n",
      "    []\n",
      "    >>> filter_by_substring_regex(['abc', 'bacd', 'cde', 'array'], 'a')\n",
      "    ['abc', 'bacd', 'array']\n",
      "    \"\"\"\n",
      "    return [s for s in strings if substring in s]\n",
      "\n",
      "\n",
      "    \"\"\" Filter an input list of strings only for ones that contain given substring\n",
      "    >>> filter_by_substring_regex_compiled([], 'a')\n",
      "    []\n",
      "    >>> filter_by_substring_regex_compiled(['abc', 'bacd', 'cde', 'array'], 'a')\n",
      "    ['abc', 'bacd', 'array']\n",
      "    \"\"\"\n",
      "    return [s for s in\u001b[0m \u001b[2mgex_compiled([], 'a')\n",
      "    []\n",
      "    >>> filter_by_substring_regex_compiled(['abc', 'bacd', 'cde', 'array'], 'a')\n",
      "    ['abc', 'bacd', 'array']\n",
      "    \"\"\"\n",
      "    return [s for s in\u001b[0m\n",
      "----------------------------------------  case=8 ----------------------------------------\n",
      "\u001b[33mfrom typing import List, Tuple\n",
      "\n",
      "\n",
      "def sum_product(numbers: List[int]) -> Tuple[int, int]:\n",
      "    \"\"\" For a given list of integers, return a tuple consisting of a sum and a product of all the integers in a list.\n",
      "    Empty sum should be equal to 0 and empty product should be equal to 1.\n",
      "    >>> sum_product([])\n",
      "    (0, 1)\n",
      "    >>> sum_product([1, 2, 3, 4])\n",
      "    (10, 24)\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-xD9gzBUAkJAf', 'object': 'text_completion', 'status': 'completed', 'created': 1701775646.63897, 'uploaded': 1701775690.849067, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    return sum(numbers), reduce(lambda x, y: x * y, numbers, 1)\\n\\n\\ndef sum_product_2(numbers: List[int]) -> Tuple[int, int]:\\n    \"\"\" For a given list of integers, return a tuple consisting of a sum and a product of all the integers in a list.\\n    Empty sum should be equal to 0 and empty product should be equal to 1.\\n    >>> sum_product_2([])\\n    (0, 1)\\n    >>> sum_product_2([1, 2, 3, 4])\\n    (10, 24)\\n    \"\"\"\\n    return sum(numbers), reduce(lambda x, y: x * y, numbers, 1)\\n\\n\\ndef sum_product_3(numbers: List[int]) -> Tuple[int, int]:\\n    \"\"\" For a given list of integers, return a tuple consisting of a sum and a product of all the integers in a list.\\n    Empty sum should be equal to 0 and empty product should be equal to 1.\\n    >>> sum_product_3([])\\n   '}]}\n",
      "\u001b[32m\n",
      "    return sum(numbers), reduce(lambda x, y: x * y, numbers, 1)\n",
      "\n",
      "\n",
      "    \"\"\" For a given list of integers, return a tuple consisting of a sum and a product of all the integers in a list.\n",
      "    Empty sum should be equal to 0 and empty product should be equal to 1.\n",
      "    >>> sum_product_2([])\n",
      "    (0, 1)\n",
      "    >>> sum_product_2([1, 2, 3, 4])\n",
      "    (10, 24)\n",
      "    \"\"\"\n",
      "    return sum(numbers), reduce(lambda x, y: x * y, numbers, 1)\n",
      "\n",
      "\n",
      "    \"\"\" For a given list of integers, return a tuple consisting of a sum and a product of all the integers in a list.\n",
      "    Empty sum should be equal to 0 and empty product should be equal to 1.\n",
      "    >>> sum_product_3([])\n",
      "   \u001b[0m \u001b[2m in a list.\n",
      "    Empty sum should be equal to 0 and empty product should be equal to 1.\n",
      "    >>> sum_product_3([])\n",
      "   \u001b[0m\n",
      "----------------------------------------  case=9 ----------------------------------------\n",
      "\u001b[33mfrom typing import List, Tuple\n",
      "\n",
      "\n",
      "def rolling_max(numbers: List[int]) -> List[int]:\n",
      "    \"\"\" From a given list of integers, generate a list of rolling maximum element found until given moment\n",
      "    in the sequence.\n",
      "    >>> rolling_max([1, 2, 3, 2, 3, 4, 2])\n",
      "    [1, 2, 3, 3, 3, 4, 4]\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-6eFQmKatz5Hc', 'object': 'text_completion', 'status': 'completed', 'created': 1701775690.906123, 'uploaded': 1701775734.944406, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    result = []\\n    for i in range(len(numbers)):\\n        if i == 0:\\n            result.append(numbers[i])\\n        else:\\n            result.append(max(result[-1], numbers[i]))\\n    return result\\n\\n\\ndef rolling_min(numbers: List[int]) -> List[int]:\\n    \"\"\" From a given list of integers, generate a list of rolling minimum element found until given moment\\n    in the sequence.\\n    >>> rolling_min([1, 2, 3, 2, 3, 4, 2])\\n    [1, 1, 1, 2, 2, 2, 2]\\n    \"\"\"\\n    result = []\\n    for i in range(len(numbers)):\\n        if i == 0:\\n            result.append(numbers[i])\\n        else:\\n            result.append(min(result[-1], numbers[i]))\\n    return result\\n\\n\\ndef rolling_max_min(numbers: List[int]) -> List[Tuple[int, int]]:\\n    \"\"\" From a given list of integers, generate a list'}]}\n",
      "\u001b[32m\n",
      "    result = []\n",
      "    for i in range(len(numbers)):\n",
      "        if i == 0:\n",
      "            result.append(numbers[i])\n",
      "        else:\n",
      "            result.append(max(result[-1], numbers[i]))\n",
      "    return result\n",
      "\n",
      "\n",
      "    \"\"\" From a given list of integers, generate a list of rolling minimum element found until given moment\n",
      "    in the sequence.\n",
      "    >>> rolling_min([1, 2, 3, 2, 3, 4, 2])\n",
      "    [1, 1, 1, 2, 2, 2, 2]\n",
      "    \"\"\"\n",
      "    result = []\n",
      "    for i in range(len(numbers)):\n",
      "        if i == 0:\n",
      "            result.append(numbers[i])\n",
      "        else:\n",
      "            result.append(min(result[-1], numbers[i]))\n",
      "    return result\n",
      "\n",
      "\n",
      "    \"\"\" From a given list of integers, generate a list\u001b[0m \u001b[2mrolling_max_min(numbers: List[int]) -> List[Tuple[int, int]]:\n",
      "    \"\"\" From a given list of integers, generate a list\u001b[0m\n",
      "----------------------------------------  case=10 ----------------------------------------\n",
      "\u001b[33m\n",
      "\n",
      "def is_palindrome(string: str) -> bool:\n",
      "    \"\"\" Test if given string is a palindrome \"\"\"\n",
      "    return string == string[::-1]\n",
      "\n",
      "\n",
      "def make_palindrome(string: str) -> str:\n",
      "    \"\"\" Find the shortest palindrome that begins with a supplied string.\n",
      "    Algorithm idea is simple:\n",
      "    - Find the longest postfix of supplied string that is a palindrome.\n",
      "    - Append to the end of the string reverse of a string prefix that comes before the palindromic suffix.\n",
      "    >>> make_palindrome('')\n",
      "    ''\n",
      "    >>> make_palindrome('cat')\n",
      "    'catac'\n",
      "    >>> make_palindrome('cata')\n",
      "    'catac'\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-xsldtuv3dEmY', 'object': 'text_completion', 'status': 'completed', 'created': 1701775734.9987397, 'uploaded': 1701775778.5835423, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    if not string:\\n        return \\'\\'\\n    if is_palindrome(string):\\n        return string\\n    for i in range(len(string), 0, -1):\\n        if is_palindrome(string[:i]):\\n            return string + string[i - 1::-1]\\n    return \\'\\'\\n\\n\\ndef make_palindrome_recursive(string: str) -> str:\\n    \"\"\" Find the shortest palindrome that begins with a supplied string.\\n    Algorithm idea is simple:\\n    - Find the longest postfix of supplied string that is a palindrome.\\n    - Append to the end of the string reverse of a string prefix that comes before the palindromic suffix.\\n    >>> make_palindrome_recursive(\\'\\')\\n    \\'\\'\\n    >>> make_palindrome_recursive(\\'cat\\')\\n    \\'catac\\'\\n    >>> make_palindrome_recursive(\\'cata\\')\\n    \\'catac\\'\\n    \"\"\"\\n    if not string:\\n        return \\'\\'\\n    if is_palindrome(string):\\n        return string\\n    for i in range'}]}\n",
      "\u001b[32m\n",
      "    if not string:\n",
      "        return ''\n",
      "    if is_palindrome(string):\n",
      "        return string\n",
      "    for i in range(len(string), 0, -1):\n",
      "        if is_palindrome(string[:i]):\n",
      "            return string + string[i - 1::-1]\n",
      "    return ''\n",
      "\n",
      "\n",
      "    \"\"\" Find the shortest palindrome that begins with a supplied string.\n",
      "    Algorithm idea is simple:\n",
      "    - Find the longest postfix of supplied string that is a palindrome.\n",
      "    - Append to the end of the string reverse of a string prefix that comes before the palindromic suffix.\n",
      "    >>> make_palindrome_recursive('')\n",
      "    ''\n",
      "    >>> make_palindrome_recursive('cat')\n",
      "    'catac'\n",
      "    >>> make_palindrome_recursive('cata')\n",
      "    'catac'\n",
      "    \"\"\"\n",
      "    if not string:\n",
      "        return ''\n",
      "    if is_palindrome(string):\n",
      "        return string\n",
      "    for i in range\u001b[0m \u001b[2me(string):\n",
      "        return string\n",
      "    for i in range\u001b[0m\n",
      "----------------------------------------  case=11 ----------------------------------------\n",
      "\u001b[33mfrom typing import List\n",
      "\n",
      "\n",
      "def string_xor(a: str, b: str) -> str:\n",
      "    \"\"\" Input are two strings a and b consisting only of 1s and 0s.\n",
      "    Perform binary XOR on these inputs and return result also as a string.\n",
      "    >>> string_xor('010', '110')\n",
      "    '100'\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-ydzsY2l4l25A', 'object': 'text_completion', 'status': 'completed', 'created': 1701775778.6486137, 'uploaded': 1701775822.1439142, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    return \\'\\'.join(map(lambda x, y: str(int(x) ^ int(y)), a, b))\\n\\n\\ndef string_xor_list(a: List[str], b: List[str]) -> List[str]:\\n    \"\"\" Input are two lists of strings a and b consisting only of 1s and 0s.\\n    Perform binary XOR on these inputs and return result also as a list of strings.\\n    >>> string_xor_list([\\'010\\', \\'110\\'], [\\'001\\', \\'101\\'])\\n    [\\'111\\', \\'100\\']\\n    \"\"\"\\n    return [string_xor(a[i], b[i]) for i in range(len(a))]\\n\\n\\ndef string_xor_matrix(a: List[List[str]], b: List[List[str]]) -> List[List[str]]:\\n    \"\"\" Input are two lists of strings a and b consisting only of 1s and 0s.\\n    Perform binary XOR on these inputs and return result also as a list of strings.\\n    >>> string_xor_matrix'}]}\n",
      "\u001b[32m\n",
      "    return ''.join(map(lambda x, y: str(int(x) ^ int(y)), a, b))\n",
      "\n",
      "\n",
      "    \"\"\" Input are two lists of strings a and b consisting only of 1s and 0s.\n",
      "    Perform binary XOR on these inputs and return result also as a list of strings.\n",
      "    >>> string_xor_list(['010', '110'], ['001', '101'])\n",
      "    ['111', '100']\n",
      "    \"\"\"\n",
      "    return [string_xor(a[i], b[i]) for i in range(len(a))]\n",
      "\n",
      "\n",
      "    \"\"\" Input are two lists of strings a and b consisting only of 1s and 0s.\n",
      "    Perform binary XOR on these inputs and return result also as a list of strings.\n",
      "    >>> string_xor_matrix\u001b[0m \u001b[2mnd b consisting only of 1s and 0s.\n",
      "    Perform binary XOR on these inputs and return result also as a list of strings.\n",
      "    >>> string_xor_matrix\u001b[0m\n",
      "----------------------------------------  case=12 ----------------------------------------\n",
      "\u001b[33mfrom typing import List, Optional\n",
      "\n",
      "\n",
      "def longest(strings: List[str]) -> Optional[str]:\n",
      "    \"\"\" Out of list of strings, return the longest one. Return the first one in case of multiple\n",
      "    strings of the same length. Return None in case the input list is empty.\n",
      "    >>> longest([])\n",
      "\n",
      "    >>> longest(['a', 'b', 'c'])\n",
      "    'a'\n",
      "    >>> longest(['a', 'bb', 'ccc'])\n",
      "    'ccc'\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-rWk11LFppJwM', 'object': 'text_completion', 'status': 'completed', 'created': 1701775822.2040331, 'uploaded': 1701775866.213426, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    if not strings:\\n        return None\\n    longest_string = strings[0]\\n    for string in strings:\\n        if len(string) > len(longest_string):\\n            longest_string = string\\n    return longest_string\\n\\n\\ndef longest_2(strings: List[str]) -> Optional[str]:\\n    \"\"\" Out of list of strings, return the longest one. Return the first one in case of multiple\\n    strings of the same length. Return None in case the input list is empty.\\n    >>> longest([])\\n\\n    >>> longest([\\'a\\', \\'b\\', \\'c\\'])\\n    \\'a\\'\\n    >>> longest([\\'a\\', \\'bb\\', \\'ccc\\'])\\n    \\'ccc\\'\\n    \"\"\"\\n    if not strings:\\n        return None\\n    longest_string = strings[0]\\n    for string in strings:\\n        if len(string) > len(longest_string):\\n            longest_string = string\\n    return longest_string\\n\\n\\ndef longest_3(strings: List[str]) -> Optional[str]:\\n    \"\"\" Out of list of strings, return the longest one. Return the first one in case of'}]}\n",
      "\u001b[32m\n",
      "    if not strings:\n",
      "        return None\n",
      "    longest_string = strings[0]\n",
      "    for string in strings:\n",
      "        if len(string) > len(longest_string):\n",
      "            longest_string = string\n",
      "    return longest_string\n",
      "\n",
      "\n",
      "    \"\"\" Out of list of strings, return the longest one. Return the first one in case of multiple\n",
      "    strings of the same length. Return None in case the input list is empty.\n",
      "    >>> longest([])\n",
      "\n",
      "    >>> longest(['a', 'b', 'c'])\n",
      "    'a'\n",
      "    >>> longest(['a', 'bb', 'ccc'])\n",
      "    'ccc'\n",
      "    \"\"\"\n",
      "    if not strings:\n",
      "        return None\n",
      "    longest_string = strings[0]\n",
      "    for string in strings:\n",
      "        if len(string) > len(longest_string):\n",
      "            longest_string = string\n",
      "    return longest_string\n",
      "\n",
      "\n",
      "    \"\"\" Out of list of strings, return the longest one. Return the first one in case of\u001b[0m \u001b[2m> Optional[str]:\n",
      "    \"\"\" Out of list of strings, return the longest one. Return the first one in case of\u001b[0m\n",
      "----------------------------------------  case=13 ----------------------------------------\n",
      "\u001b[33m\n",
      "\n",
      "def greatest_common_divisor(a: int, b: int) -> int:\n",
      "    \"\"\" Return a greatest common divisor of two integers a and b\n",
      "    >>> greatest_common_divisor(3, 5)\n",
      "    1\n",
      "    >>> greatest_common_divisor(25, 15)\n",
      "    5\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-i5hhMNWxEmXW', 'object': 'text_completion', 'status': 'completed', 'created': 1701775866.2748954, 'uploaded': 1701775909.6671665, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    while b:\\n        a, b = b, a % b\\n    return a\\n\\n\\ndef least_common_multiple(a: int, b: int) -> int:\\n    \"\"\" Return a least common multiple of two integers a and b\\n    >>> least_common_multiple(3, 5)\\n    15\\n    >>> least_common_multiple(25, 15)\\n    75\\n    \"\"\"\\n    return a * b // greatest_common_divisor(a, b)\\n\\n\\ndef greatest_common_divisor_recursive(a: int, b: int) -> int:\\n    \"\"\" Return a greatest common divisor of two integers a and b\\n    >>> greatest_common_divisor_recursive(3, 5)\\n    1\\n    >>> greatest_common_divisor_recursive(25, 15)\\n    5\\n    \"\"\"\\n    if b == 0:\\n        return a\\n    return greatest_common_divisor_recursive(b, a % b)\\n\\n\\ndef least_common_multiple_recursive(a: int, b'}]}\n",
      "\u001b[32m\n",
      "    while b:\n",
      "        a, b = b, a % b\n",
      "    return a\n",
      "\n",
      "\n",
      "    \"\"\" Return a least common multiple of two integers a and b\n",
      "    >>> least_common_multiple(3, 5)\n",
      "    15\n",
      "    >>> least_common_multiple(25, 15)\n",
      "    75\n",
      "    \"\"\"\n",
      "    return a * b // greatest_common_divisor(a, b)\n",
      "\n",
      "\n",
      "    \"\"\" Return a greatest common divisor of two integers a and b\n",
      "    >>> greatest_common_divisor_recursive(3, 5)\n",
      "    1\n",
      "    >>> greatest_common_divisor_recursive(25, 15)\n",
      "    5\n",
      "    \"\"\"\n",
      "    if b == 0:\n",
      "        return a\n",
      "    return greatest_common_divisor_recursive(b, a % b)\n",
      "\n",
      "\u001b[0m \u001b[2me(25, 15)\n",
      "    5\n",
      "    \"\"\"\n",
      "    if b == 0:\n",
      "        return a\n",
      "    return greatest_common_divisor_recursive(b, a % b)\n",
      "\n",
      "\n",
      "def least_common_multiple_recursive(a: int, b\u001b[0m\n",
      "----------------------------------------  case=14 ----------------------------------------\n",
      "\u001b[33mfrom typing import List\n",
      "\n",
      "\n",
      "def all_prefixes(string: str) -> List[str]:\n",
      "    \"\"\" Return list of all prefixes from shortest to longest of the input string\n",
      "    >>> all_prefixes('abc')\n",
      "    ['a', 'ab', 'abc']\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-eYCW7fvDSGz3', 'object': 'text_completion', 'status': 'completed', 'created': 1701775909.7286584, 'uploaded': 1701775953.2356164, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    return [string[:i] for i in range(len(string) + 1)]\\n\\ndef all_suffixes(string: str) -> List[str]:\\n    \"\"\" Return list of all suffixes from shortest to longest of the input string\\n    >>> all_suffixes(\\'abc\\')\\n    [\\'c\\', \\'bc\\', \\'abc\\']\\n    \"\"\"\\n    return [string[i:] for i in range(len(string) + 1)]\\n\\ndef all_substrings(string: str) -> List[str]:\\n    \"\"\" Return list of all substrings from shortest to longest of the input string\\n    >>> all_substrings(\\'abc\\')\\n    [\\'a\\', \\'b\\', \\'c\\', \\'ab\\', \\'bc\\', \\'abc\\']\\n    \"\"\"\\n    return [string[i:j] for i in range(len(string)) for j in range(i + 1, len(string) + 1)]\\n\\ndef all_substrings_with_overlap(string: str) -> List[str]:\\n    \"\"\" Return list of all substrings from shortest to longest of the input string\\n    with overla'}]}\n",
      "\u001b[32m\n",
      "    return [string[:i] for i in range(len(string) + 1)]\n",
      "\n",
      "    \"\"\" Return list of all suffixes from shortest to longest of the input string\n",
      "    >>> all_suffixes('abc')\n",
      "    ['c', 'bc', 'abc']\n",
      "    \"\"\"\n",
      "    return [string[i:] for i in range(len(string) + 1)]\n",
      "\n",
      "    \"\"\" Return list of all substrings from shortest to longest of the input string\n",
      "    >>> all_substrings('abc')\n",
      "    ['a', 'b', 'c', 'ab', 'bc', 'abc']\n",
      "    \"\"\"\n",
      "    return [string[i:j] for i in range(len(string)) for j in range(i + 1, len(string) + 1)]\n",
      "\n",
      "    \"\"\" Return list of all substrings from shortest to longest of the input string\n",
      "    with overla\u001b[0m \u001b[2msubstrings_with_overlap(string: str) -> List[str]:\n",
      "    \"\"\" Return list of all substrings from shortest to longest of the input string\n",
      "    with overla\u001b[0m\n",
      "----------------------------------------  case=15 ----------------------------------------\n",
      "\u001b[33m\n",
      "\n",
      "def string_sequence(n: int) -> str:\n",
      "    \"\"\" Return a string containing space-delimited numbers starting from 0 upto n inclusive.\n",
      "    >>> string_sequence(0)\n",
      "    '0'\n",
      "    >>> string_sequence(5)\n",
      "    '0 1 2 3 4 5'\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-0I5IqddBqhzM', 'object': 'text_completion', 'status': 'completed', 'created': 1701775953.2963605, 'uploaded': 1701775996.7802162, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    return \\' \\'.join(str(i) for i in range(n + 1))\\n\\n\\ndef string_sequence_2(n: int) -> str:\\n    \"\"\" Return a string containing space-delimited numbers starting from 0 upto n inclusive.\\n    >>> string_sequence_2(0)\\n    \\'0\\'\\n    >>> string_sequence_2(5)\\n    \\'0 1 2 3 4 5\\'\\n    \"\"\"\\n    return \\' \\'.join(str(i) for i in range(n + 1))\\n\\n\\ndef string_sequence_3(n: int) -> str:\\n    \"\"\" Return a string containing space-delimited numbers starting from 0 upto n inclusive.\\n    >>> string_sequence_3(0)\\n    \\'0\\'\\n    >>> string_sequence_3(5)\\n    \\'0 1 2 3 4 5\\'\\n    \"\"\"\\n    return \\' \\'.join(map(str, range(n + 1)))\\n\\n\\ndef string_sequence_4(n: int) -> str:\\n    \"\"\" Return a string containing space'}]}\n",
      "\u001b[32m\n",
      "    return ' '.join(str(i) for i in range(n + 1))\n",
      "\n",
      "\n",
      "    \"\"\" Return a string containing space-delimited numbers starting from 0 upto n inclusive.\n",
      "    >>> string_sequence_2(0)\n",
      "    '0'\n",
      "    >>> string_sequence_2(5)\n",
      "    '0 1 2 3 4 5'\n",
      "    \"\"\"\n",
      "    return ' '.join(str(i) for i in range(n + 1))\n",
      "\n",
      "\n",
      "    \"\"\" Return a string containing space-delimited numbers starting from 0 upto n inclusive.\n",
      "    >>> string_sequence_3(0)\n",
      "    '0'\n",
      "    >>> string_sequence_3(5)\n",
      "    '0 1 2 3 4 5'\n",
      "    \"\"\"\n",
      "    return ' '.join(map(str, range(n + 1)))\n",
      "\n",
      "\n",
      "    \"\"\" Return a string containing space\u001b[0m \u001b[2m ' '.join(map(str, range(n + 1)))\n",
      "\n",
      "\n",
      "def string_sequence_4(n: int) -> str:\n",
      "    \"\"\" Return a string containing space\u001b[0m\n",
      "----------------------------------------  case=16 ----------------------------------------\n",
      "\u001b[33m\n",
      "\n",
      "def count_distinct_characters(string: str) -> int:\n",
      "    \"\"\" Given a string, find out how many distinct characters (regardless of case) does it consist of\n",
      "    >>> count_distinct_characters('xyzXYZ')\n",
      "    3\n",
      "    >>> count_distinct_characters('Jerry')\n",
      "    4\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-SmBAZRWWWcfa', 'object': 'text_completion', 'status': 'completed', 'created': 1701775996.838559, 'uploaded': 1701776040.4516718, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    return len(set(string.lower()))\\n\\n\\ndef count_distinct_characters_set(string: str) -> int:\\n    \"\"\" Given a string, find out how many distinct characters (regardless of case) does it consist of\\n    >>> count_distinct_characters_set(\\'xyzXYZ\\')\\n    3\\n    >>> count_distinct_characters_set(\\'Jerry\\')\\n    4\\n    \"\"\"\\n    return len(set(string.lower()))\\n\\n\\ndef count_distinct_characters_dict(string: str) -> int:\\n    \"\"\" Given a string, find out how many distinct characters (regardless of case) does it consist of\\n    >>> count_distinct_characters_dict(\\'xyzXYZ\\')\\n    3\\n    >>> count_distinct_characters_dict(\\'Jerry\\')\\n    4\\n    \"\"\"\\n    return len(set(string.lower()))\\n\\n\\ndef count_distinct_characters_counter(string: str) -> int:\\n    \"\"\" Given a string, find out how many distinct characters (regardless of case) does it consist of\\n'}]}\n",
      "\u001b[32m\n",
      "    return len(set(string.lower()))\n",
      "\n",
      "\n",
      "    \"\"\" Given a string, find out how many distinct characters (regardless of case) does it consist of\n",
      "    >>> count_distinct_characters_set('xyzXYZ')\n",
      "    3\n",
      "    >>> count_distinct_characters_set('Jerry')\n",
      "    4\n",
      "    \"\"\"\n",
      "    return len(set(string.lower()))\n",
      "\n",
      "\n",
      "    \"\"\" Given a string, find out how many distinct characters (regardless of case) does it consist of\n",
      "    >>> count_distinct_characters_dict('xyzXYZ')\n",
      "    3\n",
      "    >>> count_distinct_characters_dict('Jerry')\n",
      "    4\n",
      "    \"\"\"\n",
      "    return len(set(string.lower()))\n",
      "\n",
      "\n",
      "    \"\"\" Given a string, find out how many distinct characters (regardless of case) does it consist of\n",
      "\u001b[0m \u001b[2mer()))\n",
      "\n",
      "\n",
      "def count_distinct_characters_counter(string: str) -> int:\n",
      "    \"\"\" Given a string, find out how many distinct characters (regardless of case) does it consist of\n",
      "\u001b[0m\n",
      "----------------------------------------  case=17 ----------------------------------------\n",
      "\u001b[33mfrom typing import List\n",
      "\n",
      "\n",
      "def parse_music(music_string: str) -> List[int]:\n",
      "    \"\"\" Input to this function is a string representing musical notes in a special ASCII format.\n",
      "    Your task is to parse this string and return list of integers corresponding to how many beats does each\n",
      "    not last.\n",
      "\n",
      "    Here is a legend:\n",
      "    'o' - whole note, lasts four beats\n",
      "    'o|' - half note, lasts two beats\n",
      "    '.|' - quater note, lasts one beat\n",
      "\n",
      "    >>> parse_music('o o| .| o| o| .| .| .| .| o o')\n",
      "    [4, 2, 1, 2, 2, 1, 1, 1, 1, 4, 4]\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-4V9BSyqpfPNl', 'object': 'text_completion', 'status': 'completed', 'created': 1701776040.5097296, 'uploaded': 1701776084.1956291, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    music_string = music_string.replace(\\' \\', \\'\\')\\n    music_list = []\\n    for char in music_string:\\n        if char == \\'o\\':\\n            music_list.append(4)\\n        elif char == \\'o|\\':\\n            music_list.append(2)\\n        elif char == \\'.|\\':\\n            music_list.append(1)\\n        else:\\n            raise ValueError(\\'Invalid character in music string\\')\\n    return music_list\\n\\n\\ndef beat_count(music_list: List[int]) -> int:\\n    \"\"\" Input to this function is a list of integers representing musical notes.\\n    Your task is to return the total number of beats in the music.\\n\\n    >>> beat_count([4, 2, 1, 2, 2, 1, 1, 1, 1, 4, 4])\\n    20\\n    \"\"\"\\n    return sum(music_list)\\n\\n\\ndef beat_count_2(music_list: List[int]) -> int:\\n    \"\"\" Input to this function is a list of integers representing musical notes.\\n    Your'}]}\n",
      "\u001b[32m\n",
      "    music_string = music_string.replace(' ', '')\n",
      "    music_list = []\n",
      "    for char in music_string:\n",
      "        if char == 'o':\n",
      "            music_list.append(4)\n",
      "        elif char == 'o|':\n",
      "            music_list.append(2)\n",
      "        elif char == '.|':\n",
      "            music_list.append(1)\n",
      "        else:\n",
      "            raise ValueError('Invalid character in music string')\n",
      "    return music_list\n",
      "\n",
      "\n",
      "    \"\"\" Input to this function is a list of integers representing musical notes.\n",
      "    Your task is to return the total number of beats in the music.\n",
      "\n",
      "    >>> beat_count([4, 2, 1, 2, 2, 1, 1, 1, 1, 4, 4])\n",
      "    20\n",
      "    \"\"\"\n",
      "    return sum(music_list)\n",
      "\n",
      "\n",
      "    \"\"\" Input to this function is a list of integers representing musical notes.\n",
      "    Your\u001b[0m \u001b[2mint:\n",
      "    \"\"\" Input to this function is a list of integers representing musical notes.\n",
      "    Your\u001b[0m\n",
      "----------------------------------------  case=18 ----------------------------------------\n",
      "\u001b[33m\n",
      "\n",
      "def how_many_times(string: str, substring: str) -> int:\n",
      "    \"\"\" Find how many times a given substring can be found in the original string. Count overlaping cases.\n",
      "    >>> how_many_times('', 'a')\n",
      "    0\n",
      "    >>> how_many_times('aaa', 'a')\n",
      "    3\n",
      "    >>> how_many_times('aaaa', 'aa')\n",
      "    3\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-kGRqPHb3lYI9', 'object': 'text_completion', 'status': 'completed', 'created': 1701776084.2561798, 'uploaded': 1701776127.6975503, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    if not substring:\\n        return 0\\n    if not string:\\n        return 0\\n    if len(substring) > len(string):\\n        return 0\\n    if substring == string:\\n        return 1\\n    count = 0\\n    for i in range(len(string) - len(substring) + 1):\\n        if string[i:i + len(substring)] == substring:\\n            count += 1\\n    return count\\n\\n\\ndef how_many_times_no_overlap(string: str, substring: str) -> int:\\n    \"\"\" Find how many times a given substring can be found in the original string. Do not count overlaping cases.\\n    >>> how_many_times_no_overlap(\\'\\', \\'a\\')\\n    0\\n    >>> how_many_times_no_overlap(\\'aaa\\', \\'a\\')\\n    1\\n    >>> how_many_times_no_overlap(\\'aaaa\\', \\'aa\\')\\n    2\\n    \"\"\"\\n    if not substring:\\n        return 0\\n    if not string:\\n        return 0\\n    if len(substring) > len('}]}\n",
      "\u001b[32m\n",
      "    if not substring:\n",
      "        return 0\n",
      "    if not string:\n",
      "        return 0\n",
      "    if len(substring) > len(string):\n",
      "        return 0\n",
      "    if substring == string:\n",
      "        return 1\n",
      "    count = 0\n",
      "    for i in range(len(string) - len(substring) + 1):\n",
      "        if string[i:i + len(substring)] == substring:\n",
      "            count += 1\n",
      "    return count\n",
      "\n",
      "\n",
      "    \"\"\" Find how many times a given substring can be found in the original string. Do not count overlaping cases.\n",
      "    >>> how_many_times_no_overlap('', 'a')\n",
      "    0\n",
      "    >>> how_many_times_no_overlap('aaa', 'a')\n",
      "    1\n",
      "    >>> how_many_times_no_overlap('aaaa', 'aa')\n",
      "    2\n",
      "    \"\"\"\n",
      "    if not substring:\n",
      "        return 0\n",
      "    if not string:\n",
      "        return 0\n",
      "    if len(substring) > len(\u001b[0m \u001b[2m 0\n",
      "    if not string:\n",
      "        return 0\n",
      "    if len(substring) > len(\u001b[0m\n",
      "----------------------------------------  case=19 ----------------------------------------\n",
      "\u001b[33mfrom typing import List\n",
      "\n",
      "\n",
      "def sort_numbers(numbers: str) -> str:\n",
      "    \"\"\" Input is a space-delimited string of numberals from 'zero' to 'nine'.\n",
      "    Valid choices are 'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight' and 'nine'.\n",
      "    Return the string with numbers sorted from smallest to largest\n",
      "    >>> sort_numbers('three one five')\n",
      "    'one three five'\n",
      "    \"\"\u001b[0m\n",
      "{'id': 'comp-6beiQvecMc1R', 'object': 'text_completion', 'status': 'completed', 'created': 1701776127.7569404, 'uploaded': 1701776171.1451578, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '\\n    # TODO: Implement this function\\n    return \"\"\\n\\n\\ndef sort_words(words: str) -> str:\\n    \"\"\" Input is a space-delimited string of words.\\n    Return the string with words sorted from smallest to largest\\n    >>> sort_words(\\'three one five\\')\\n    \\'five one three\\'\\n    \"\"\"\\n    # TODO: Implement this function\\n    return \"\"\\n\\n\\ndef sort_words_by_length(words: str) -> str:\\n    \"\"\" Input is a space-delimited string of words.\\n    Return the string with words sorted by length from smallest to largest\\n    >>> sort_words_by_length(\\'three one five\\')\\n    \\'one three five\\'\\n    \"\"\"\\n    # TODO: Implement this function\\n    return \"\"\\n\\n\\ndef sort_words_by_length_reverse(words: str) -> str:\\n    \"\"\" Input is a space-delimited string of words.\\n    Return the string with words sorted by length from largest to smallest\\n    >>> sort_words_by_length_reverse(\\'three one five\\')\\n    \\'five three one\\'\\n    \"\"\"\\n    #'}]}\n",
      "\u001b[32m\n",
      "    # TODO: Implement this function\n",
      "    return \"\"\n",
      "\n",
      "\n",
      "    \"\"\" Input is a space-delimited string of words.\n",
      "    Return the string with words sorted from smallest to largest\n",
      "    >>> sort_words('three one five')\n",
      "    'five one three'\n",
      "    \"\"\"\n",
      "    # TODO: Implement this function\n",
      "    return \"\"\n",
      "\n",
      "\n",
      "    \"\"\" Input is a space-delimited string of words.\n",
      "    Return the string with words sorted by length from smallest to largest\n",
      "    >>> sort_words_by_length('three one five')\n",
      "    'one three five'\n",
      "    \"\"\"\n",
      "    # TODO: Implement this function\n",
      "    return \"\"\n",
      "\n",
      "\n",
      "    \"\"\" Input is a space-delimited string of words.\n",
      "    Return the string with words sorted by length from largest to smallest\n",
      "    >>> sort_words_by_length_reverse('three one five')\n",
      "    'five three one'\n",
      "    \"\"\"\n",
      "    #\u001b[0m \u001b[2ms sorted by length from largest to smallest\n",
      "    >>> sort_words_by_length_reverse('three one five')\n",
      "    'five three one'\n",
      "    \"\"\"\n",
      "    #\u001b[0m\n",
      "----------------------------------------  case=20 ----------------------------------------\n",
      "\u001b[33mfrom typing import List, Tuple\n",
      "\n",
      "\n",
      "def find_closest_elements(numbers: List[float]) -> Tuple[float, float]:\n",
      "    \"\"\" From a supplied list of numbers (of length at least two) select and return two that are the closest to each\n",
      "    other and return them in order (smaller number, larger number).\n",
      "    >>> find_closest_elements([1.0, 2.0, 3.0, 4.0, 5.0, 2.2])\n",
      "    (2.0, 2.2)\n",
      "    >>> find_closest_elements([1.0, 2.0, 3.0, 4.0, 5.0, 2.0])\n",
      "    (2.0, 2.0)\n",
      "    \"\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "postfix = \"\"\n",
    "\n",
    "t0 = time.time()\n",
    "problems = list(read_problems().values()) * TIMES\n",
    "output = []\n",
    "\n",
    "\n",
    "for i, case_ in enumerate(problems):\n",
    "    case = deepcopy(case_)\n",
    "    print(\"-\" * 40, f\" case={i}\", \"-\" * 40)\n",
    "    test_by_continuing(case)\n",
    "    output.append(case)\n",
    "\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "output_name = f\"human-continue{postfix}.jsonl\"\n",
    "write_jsonl(output_name, output)\n",
    "\n",
    "res = subprocess.check_output(f\"evaluate_functional_correctness {output_name}\", shell=True)\n",
    "metrics = json.loads(res.decode('utf-8').strip().split('\\n')[-1].replace(\"'\", '\"'))\n",
    "print(termcolor.colored(metrics, \"magenta\"))\n",
    "\n",
    "tmp = f\"method=continue temperature={TEMPERATURE} top_p={TOP_P} postfix='{postfix}' times={TIMES}  {metrics} {(t1 - t0):.2f} {MODEL}\\n\"\n",
    "\n",
    "with open(\"human-eval-all-results.txt\", \"a\") as f:\n",
    "    f.write(tmp)\n",
    "\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feeabad-4c22-4013-b4d2-e9cd31513c50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MPI variant of continue_human_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e60d05-c89c-42b4-93c4-4165cd4c103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys, termcolor, subprocess, json, time, random\n",
    "from copy import deepcopy\n",
    "from mpi4py import MPI\n",
    "from human_eval.data import write_jsonl, read_problems\n",
    "from human_eval.data import read_problems\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"~/workspace/capstone-code-generation/evaluation_framework\")\n",
    "from config import config_dict, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9413c6d-dda1-4f38-9f69-1d7254a75908",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad37f27-05ee-455b-bc4c-5c5f703ed3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "#MODEL = \"smallcloudai/Refact-1_6B-fim\"\n",
    "# MODEL = \"Refact/1.6B\"\n",
    "#MODEL = \"codellama/7b/lora-20231026-161421\"\n",
    "#MODEL = \"codellama/7b\"\n",
    "MODEL = \"codellama/7b/lora-20231107-201630\"\n",
    "\n",
    "\n",
    "\n",
    "TEMPERATURE = 0.2\n",
    "TOP_P = 0.95\n",
    "TIMES = 1\n",
    "MAX_TOKENS = 256\n",
    "INFERENCE_ENDPOINT = 'http://127.0.0.1:8008'\n",
    "\n",
    "metadata = {\n",
    "    'MODEL': MODEL,\n",
    "    'TEMPERATURE': TEMPERATURE,\n",
    "    'TOP_P': TOP_P,\n",
    "    'TIMES': TIMES,\n",
    "    'MAX_TOKENS': MAX_TOKENS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3aaaa8-c7ee-4984-87dc-332fe5056d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def run_completion_call(src_txt):\n",
    "    res = requests.post(f\"{INFERENCE_ENDPOINT}/v1/completions\", json={\n",
    "        \"model\": MODEL,\n",
    "        \"max_tokens\": MAX_TOKENS,\n",
    "        \"stream\": False,\n",
    "        \"echo\": True,\n",
    "        \"top_p\": TOP_P,\n",
    "        \"temperature\": TEMPERATURE,\n",
    "        \"prompt\": src_txt,\n",
    "        \"stop\": [\"\\n\\n\\n\"],\n",
    "    })\n",
    "    res.raise_for_status()\n",
    "    j = res.json()\n",
    "    # print(j)\n",
    "    return j[\"choices\"][0][\"text\"]\n",
    "\n",
    "\n",
    "def test_by_continuing(comm, case):\n",
    "    orig = case[\"prompt\"].rstrip()\n",
    "    print_me = termcolor.colored(orig[:-1], \"yellow\")\n",
    "    if comm.size == 1:\n",
    "        print(print_me)\n",
    "    t = run_completion_call(orig)\n",
    "    uncut = t\n",
    "    lines = t.split(\"\\n\")\n",
    "    filtered = []\n",
    "    for x in lines:\n",
    "        if x.startswith(\" \") or x.strip() == \"\":\n",
    "            filtered.append(x)\n",
    "        elif not x.startswith(\" \"):\n",
    "            break\n",
    "    t = \"\\n\".join(filtered)\n",
    "    assert uncut.startswith(t)\n",
    "    print_response = termcolor.colored(t, \"green\") + \" \" + termcolor.colored(uncut[len(t):], attrs=[\"dark\"])\n",
    "    if comm.size == 1:\n",
    "        print(print_response)\n",
    "    else:\n",
    "        print(print_me + \"\\n\" + print_response)\n",
    "    case[\"completion\"] = t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4238a-c22a-42db-b01e-037f07a88553",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af813a1-0aa9-4141-a8d5-3c0ecda6c5d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# main body of measure_humaneval_continue.py\n",
    "t0 = time.time()\n",
    "from human_eval.data import write_jsonl, read_problems\n",
    "from human_eval.data import read_problems\n",
    "problems = list(read_problems().values()) * TIMES\n",
    "comm = MPI.COMM_WORLD\n",
    "my_problems = problems[comm.rank::comm.size]\n",
    "output = []\n",
    "for i, case_ in enumerate(my_problems):\n",
    "    case = deepcopy(case_)\n",
    "    print(\"-\" * 40, \" rank=%i case=%i\" % (comm.rank, i), \"-\" * 40)\n",
    "    test_by_continuing(comm, case)\n",
    "    output.append(case)\n",
    "comm.barrier()\n",
    "t1 = time.time()\n",
    "tmp = comm.gather(output, root=0)\n",
    "if comm.rank == 0:\n",
    "    all_output = [x for y in tmp for x in y]\n",
    "    output_name = \"human-%s%s.jsonl\" % (\"continue\", postfix)\n",
    "    write_jsonl(output_name, all_output)\n",
    "    res = subprocess.check_output(f\"evaluate_functional_correctness {output_name}\", shell=True)\n",
    "    metrics = json.loads(res.decode('utf-8').strip().split('\\n')[-1].replace(\"'\", '\"'))\n",
    "    print(termcolor.colored(metrics, \"magenta\"))\n",
    "    tmp = \"method=%s temperature=%0.2f top_p=%0.2f postfix='%s' world=%i times=%i  %s %0.2fs %s\\n\" % (\n",
    "        \"continue\", TEMPERATURE, TOP_P, postfix, comm.size, TIMES, metrics, (t1 - t0), MODEL)\n",
    "    with open(\"human-eval-all-results.txt\", \"a\") as f:\n",
    "        f.write(tmp)\n",
    "    print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f2314-8d2f-4c4c-b171-b6395813c418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672f231-c7ce-444c-be18-c0efa89fc02b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbd3bd22",
   "metadata": {},
   "source": [
    "## Non-MPI Variant: Run /completions endpoint on prompts, test code for generate_responses.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705e55a3-6e8d-4f2a-aede-e8c925a1e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Imports\n",
    "import sys, termcolor, subprocess, json, time, random\n",
    "from copy import deepcopy\n",
    "from mpi4py import MPI\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Shared config from across project\n",
    "from config import config_dict, logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c87d6e-37dc-4d69-91e9-913986925de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline_steps_to_run': ['split_train_test',\n",
       "  'make_prompts',\n",
       "  'generate_responses',\n",
       "  'evaluate_responses'],\n",
       " 'code_base_directory': '../snap_v4_clone/',\n",
       " 'train_ratio': 0.8,\n",
       " 'output_directory': 'data_produced_by_eval_fram/',\n",
       " 'seed': 0,\n",
       " 'split_strategy': 'random',\n",
       " 'num_label_tokens': 2,\n",
       " 'tokens_prompts_count': 1000,\n",
       " 'num_label_lines': 2,\n",
       " 'lines_prompts_count': 1000,\n",
       " 'methods_prompts_count': 100,\n",
       " 'infill': True,\n",
       " 'max_lines_above': 50,\n",
       " 'max_lines_below': 50,\n",
       " 'prompt_directory': 'data/prompts/',\n",
       " 'token_masking_strategies': ['token_infill', 'line_infill', 'method_infill'],\n",
       " 'models': ['code_llama_7b_fine_tuned'],\n",
       " 'generated_responses_directory': 'data/generated_responses/',\n",
       " 'inference_model': 'codellama/7b/lora-20231107-201630',\n",
       " 'inference_temperature': 0.2,\n",
       " 'inference_top_p': 0.95,\n",
       " 'inference_times': 1,\n",
       " 'inference_max_tokens': 256,\n",
       " 'evaluation_metrics': ['pass@k'],\n",
       " 'evaluation_directory': 'data/evaluate_responses/'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ef892f7-098a-4252-8c64-ff00670e5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "#MODEL = \"smallcloudai/Refact-1_6B-fim\"\n",
    "#MODEL = \"Refact/1.6B\"\n",
    "#MODEL = \"codellama/7b\"\n",
    "#MODEL = \"codellama/7b/lora-20231107-201630\"\n",
    "#PROMPT_FILE = \"methods_df_10_30.csv\"\n",
    "\n",
    "# PROMPT_FILE = config_dict['prompt_file'] ToDo - capture prompt file\n",
    "# for logging\n",
    "\n",
    "# Global config, can be overridden via function arguments to \n",
    "# evaluation_framework function.\n",
    "PROMPTS_PATH = config_dict['prompt_directory']\n",
    "GENERATED_RESPONSES_DIRECTORY = config_dict['generated_responses_directory']\n",
    "MODEL = config_dict['inference_model']\n",
    "TEMPERATURE = config_dict['inference_temperature']\n",
    "TOP_P = config_dict['inference_top_p']\n",
    "TIMES = config_dict['inference_times']\n",
    "MAX_TOKENS = config_dict['inference_max_tokens']\n",
    "\n",
    "metadata = {\n",
    "    'MODEL': MODEL,\n",
    "    'TEMPERATURE': TEMPERATURE,\n",
    "    'TOP_P': TOP_P,\n",
    "    'TIMES': TIMES,\n",
    "    'MAX_TOKENS': MAX_TOKENS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9c88dc7-fb70-47e7-a003-b4b705ee1e7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MODEL': 'codellama/7b/lora-20231107-201630',\n",
       " 'TEMPERATURE': 0.2,\n",
       " 'TOP_P': 0.95,\n",
       " 'TIMES': 1,\n",
       " 'MAX_TOKENS': 256}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aae2f441-511c-4fac-8d39-643dd3de4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "def run_completion_call(src_txt,\n",
    "                        model,\n",
    "                        max_tokens,\n",
    "                        top_p,\n",
    "                        temperature):\n",
    "    \"\"\" Execute a single call to refact /v1/completions API\n",
    "\n",
    "    Keyword arguments:\n",
    "    src_txt -- prompt to be fed to refact hosted model. The Completion\n",
    "    API assumes that prompt is a completion-oriented prompt, typically\n",
    "    of the form <PRE> ... text ... <SUF> .. text .. <MID>. It is the \n",
    "    model's task to \"fill in the missing text between <PRE> and <SUF>.\n",
    "    \"\"\"\n",
    "    res = requests.post(f\"{INFERENCE_ENDPOINT}/v1/completions\", json={\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"stream\": False,\n",
    "        \"echo\": True,\n",
    "        \"top_p\": top_p,\n",
    "        \"temperature\": temperature,\n",
    "        \"prompt\": src_txt,\n",
    "        \"use_fast_kernels\": True,\n",
    "        \"stop\": [\"\\n\\n\\n\"],\n",
    "    })\n",
    "    res.raise_for_status()\n",
    "    j = res.json()\n",
    "    print(j)\n",
    "    return j[\"choices\"][0][\"text\"]\n",
    "\n",
    "\n",
    "def generate_responses(output_directory = GENERATED_RESPONSES_DIRECTORY,\n",
    "                       prompts_path = PROMPTS_PATH,\n",
    "                       model = MODEL,\n",
    "                       temperature = TEMPERATURE,\n",
    "                       top_p = TOP_P,\n",
    "                       times = TIMES,\n",
    "                       logprobs = False,\n",
    "                       max_tokens = MAX_TOKENS):\n",
    "    \"\"\" Given an output directory, generate responses via inference\n",
    "    and writes responses to the output directory.\n",
    "\n",
    "    Keyword arguments:\n",
    "    output_directory -- directory to write responses, default specified\n",
    "                        in config.py\n",
    "    prompts_path -- directory to find prompt files. default specified\n",
    "                    in config.py.\n",
    "    prompt_file -- alternative, specify a specific prompt file. If\n",
    "                   prompt file is specified, the batch directory\n",
    "                   approach is overriden. No default.\n",
    "    model -- specify model to be run format examples: 'codellama' or\n",
    "             'codellama/7b/lora-20231107-201630' in the case of a fine\n",
    "             tuned model. Default specified in config.py.\n",
    "    temperature -- temperature for chosen model. Default specified in \n",
    "                   config.py\n",
    "    top_p -- Top P cutoff for token selection. Default specified in \n",
    "             config.py\n",
    "    times -- Number of inference calls for the prompt, supporting\n",
    "             sampling of outputs. Default specified in config.py\n",
    "    max_tokens - Maximum number of tokens to be generated. Default\n",
    "                 specified in config.py.\n",
    "    \"\"\"\n",
    "    # ToDo: Add in ability to specify a specific prompts file and output directory for testing\n",
    "    logger.info(\"Generate responses\")\n",
    "\n",
    "    # Process all prompt files in prompts/ directory\n",
    "    for file in os.listdir(prompts_path):\n",
    "        if file != 'skipped_files.csv':\n",
    "            file_path = os.path.join(prompts_path, file)\n",
    "            # Prompt dataframe. Columns are expected to be labeled\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Loop over prompts dataframe, run inference to complete infilling\n",
    "            # After each file is complete, write new .csv with inference output\n",
    "            # as new column. Additionally write corresponding metadata file.\n",
    "            completion_output = []\n",
    "            for i in range(0,len(df)):\n",
    "             \n",
    "                # prompt from input dataframe\n",
    "                prompt = df.iloc[i][\"prompt\"]\n",
    "                print_prompt = termcolor.colored(prompt, \"yellow\") \n",
    "\n",
    "                print(\"\\n\", \"Prompt:\",\"\\n\",print_prompt)\n",
    "\n",
    "                # run inference with prompt\n",
    "                t = run_completion_call(prompt,\n",
    "                                        model,\n",
    "                                        max_tokens,\n",
    "                                        top_p,\n",
    "                                        temperature)\n",
    "\n",
    "                # add response to list\n",
    "                completion_output.append(t)\n",
    "\n",
    "                # Print response together with prompt and label\n",
    "            \n",
    "                print_response = termcolor.colored(t, \"green\")\n",
    "\n",
    "                print(\"\\n\", \"Inference output:\", \"\\n\", print_response)\n",
    "                print(\"\\n\", \"Label:\",\"\\n\", df.iloc[i][\"label\"])\n",
    "\n",
    "            # Add generated output back to original DataFrame\n",
    "            df['Completion'] = completion_output\n",
    "\n",
    "            # # Write inference output to .csv\n",
    "            # timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "            # inference_output_filename = f\"{output_directory}{timestamp}_{model.replace('/', '-')}_output.csv\"\n",
    "            # df.to_csv(inference_output_filename, index=False)\n",
    "\n",
    "            # # Write metadata to a JSON file\n",
    "            # metadata_output_filename = f\"{output_directory}{timestamp}_{model.replace('/', '-')}_metadata.json\"\n",
    "            # with open(metadata_output_filename, 'w') as meta_file:\n",
    "            #     json.dump(metadata, meta_file, indent=4)\n",
    "\n",
    "            try:\n",
    "                # Write inference output to .csv\n",
    "                timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "                model_filename = model.replace('/', '-')  # Replace forward slashes in model name\n",
    "                inference_output_filename = os.path.join(output_directory, f\"{timestamp}_{model_filename}_output.csv\")\n",
    "            \n",
    "                # Check if the directory exists, create if not\n",
    "                if not os.path.exists(output_directory):\n",
    "                    os.makedirs(output_directory)\n",
    "            \n",
    "                df.to_csv(inference_output_filename, index=False)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while writing the CSV file: {e}\")\n",
    "            \n",
    "            try:\n",
    "                # Write metadata to a JSON file\n",
    "                metadata_output_filename = os.path.join(output_directory, f\"{timestamp}_{model_filename}_metadata.json\")\n",
    "                \n",
    "                with open(metadata_output_filename, 'w') as meta_file:\n",
    "                    json.dump(metadata, meta_file, indent=4)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while writing the JSON file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "737e989c-bfa0-43d0-9c6b-e8d410ce73be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/generated_responses/20231127-044918_codellama-7b-lora-20231107-201630_output.csv\n"
     ]
    }
   ],
   "source": [
    "# OSError: Cannot save file into a non-existent directory: 'example_prompts20231127-012314codellama/7b'\n",
    "#!ls ./example_prompts\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "inference_output_filename = f\"{GENERATED_RESPONSES_DIRECTORY}{timestamp}_{MODEL.replace('/', '-')}_output.csv\"\n",
    "\n",
    "print(inference_output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4407faf0-27c6-4024-b1d7-bde01a13b810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline_steps_to_run': ['split_train_test',\n",
       "  'make_prompts',\n",
       "  'generate_responses',\n",
       "  'evaluate_responses'],\n",
       " 'code_base_directory': '../snap_v4_clone/',\n",
       " 'train_ratio': 0.8,\n",
       " 'output_directory': 'data_produced_by_eval_fram/',\n",
       " 'seed': 0,\n",
       " 'split_strategy': 'random',\n",
       " 'num_label_tokens': 2,\n",
       " 'tokens_prompts_count': 1000,\n",
       " 'num_label_lines': 2,\n",
       " 'lines_prompts_count': 1000,\n",
       " 'methods_prompts_count': 100,\n",
       " 'infill': True,\n",
       " 'max_lines_above': 50,\n",
       " 'max_lines_below': 50,\n",
       " 'prompt_directory': 'data/prompts/',\n",
       " 'token_masking_strategies': ['token_infill', 'line_infill', 'method_infill'],\n",
       " 'models': ['code_llama_7b_fine_tuned'],\n",
       " 'generated_responses_directory': 'data/generated_responses/',\n",
       " 'inference_model': 'codellama/7b/lora-20231107-201630',\n",
       " 'inference_temperature': 0.2,\n",
       " 'inference_top_p': 0.95,\n",
       " 'inference_times': 1,\n",
       " 'inference_max_tokens': 256,\n",
       " 'evaluation_metrics': ['pass@k'],\n",
       " 'evaluation_directory': 'data/evaluate_responses/'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "246faed1-9e20-4148-a32f-6540f2bb8a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 04:55:26,242 - INFO - Generate responses\n",
      "2023-11-27 04:55:26,245 - DEBUG - Starting new HTTP connection (1): 127.0.0.1:8008\n",
      "2023-11-27 04:55:26,248 - DEBUG - http://127.0.0.1:8008 \"POST /v1/completions HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prompt: \n",
      " \u001b[33m<PRE>     }\n",
      "\n",
      "    // TODO: Please note that this function need to be removed once TableOptions Feature\n",
      "    // is implemented for the SCD2 and MERGE INTO snaps.\n",
      "    protected void createHashDistributionColumn(PropertyBuilder builder) {\n",
      "        builder.describe(HASH_DISTRIBUTION_COLUMN_PROP,\n",
      "                HASH_DISTRIBUTION_COLUMN_LABEL,\n",
      "                HASH_DISTRIBUTION_COLUMN_DESC)\n",
      "                .expression()\n",
      "                .add();\n",
      "    }\n",
      "\n",
      "    private void createInputSourceAliasProperty(final PropertyBuilder builder) {\n",
      "        builder.describe(SCD2_SOURCE_TABLE_ALIAS_PROP,\n",
      "                SCD2_SOURCE_TABLE_ALIAS_LABEL,\n",
      "                SCD2_SOURCE_TABLE_ALIAS_DESC)\n",
      "                .type(SnapType.STRING)\n",
      "                .expression()\n",
      "                .add();\n",
      "    }\n",
      "\n",
      "    private void createSCD2TableActionProperty(final PropertyBuilder builder) {\n",
      "        builder.describe(SCD_TABLE_ACTION_PROP, SCD_TABLE_ACTION_LABEL, SCD_TABLE_ACTION_DESC)\n",
      "                .withAllowedValues(SCD_TABLE_ACTION_TYPE)\n",
      "                .defaultValue(MERGE_INTO_TARGET_TABLE)\n",
      "                .add();\n",
      "    }\n",
      "\n",
      "    private void createTableColumnListProperty(final PropertyBuilder builder) {\n",
      "        SnapProperty columnNameProp = builder.describe(TABLE_COLUMN_PROP, TABLE_COLUMN_LABEL,\n",
      "                TABLE_COLUMN_DESC)\n",
      "                .withSuggestions(new ColumnNamesSuggestProvider(this, TABLE_COLUMN_PROP,\n",
      "                        TABLE_COLUMN_LIST_PROP))\n",
      "                .expression()\n",
      "                .build();\n",
      "        SnapProperty columnDataTypeProp = builder.describe(DATA_TYPE_PROP, DATA_TYPE_LABEL,\n",
      "                DATA_TYPE_DESC)\n",
      "                .expression()\n",
      "                .enableIf(DATA_TYPE_ENABLE_COND)\n",
      "                .withSuggestions((suggestionBuilder, propertyValues) -> suggestionBuilder\n",
      "                        .node(TABLE_COLUMN_LIST_PROP)\n",
      "                        .over(DATA_TYPE_PROP)\n",
      "                        .suggestions(SupportedDataTypesUtils.getSupportedDataTypes(getName())))\n",
      "                .build();\n",
      "        SnapProperty alterColumnProp = builder.describe(ALTER_COLUMN_PROP, ALTER_COLUMN_LABEL,\n",
      "                ALTER_COLUMN_DESC)\n",
      "                .withAllowedValues(ALTER_COLUMN_MODIFIERS)\n",
      "                .enableIf(ALTER_COLUMN_ENABLE_COND)\n",
      "                .defaultValue(ADD)\n",
      "                .build();\n",
      " <SUF>                .withEntry(alterColumnProp)\n",
      "                .add();\n",
      "    }\n",
      "\n",
      "    private void createSCD2NullHandlingProperty(final PropertyBuilder builder) {\n",
      "        builder.describe(SCD2_NULL_HANDLING_PROP,\n",
      "                         SCD2_NULL_VALUE_BEHAVIOR_LABEL,\n",
      "                         SCD2_NULL_VALUE_BEHAVIOR_DESC)\n",
      "                .withAllowedValues(SCD2_NULL_HANDLING_OPTIONS)\n",
      "                .defaultValue(SCD2_HONOR_NULLS)\n",
      "                .add();\n",
      "    }\n",
      "\n",
      "    private void createSCD2InvalidRowHandlingProperty(final PropertyBuilder builder) {\n",
      "        builder.describe(SCD2_INVALID_ROW_HANDLING_PROP,\n",
      "                         SCD2_INVALID_ROW_HANDLING_LABEL,\n",
      "                         SCD2_INVALID_ROW_HANDLING_DESC)\n",
      "                .withAllowedValues(SCD2_INVALID_ROW_HANDLING_OPTIONS)\n",
      "                .defaultValue(SCD2_IGNORE_INVALID_ROWS)\n",
      "                .add();\n",
      "    }\n",
      "\n",
      "    private void createSCD2Properties(final PropertyBuilder builder) {\n",
      "        SnapProperty naturalKeyProperty = builder.describe(NATURAL_KEY_PROP, NATURAL_KEYS_LABEL,\n",
      "                NATURAL_KEYS_DESC)\n",
      "                .type(SnapType.STRING)\n",
      "                .expression()\n",
      "                .withSuggestions(new ColumnNamesSuggestProvider(this, NATURAL_KEY_PROP,\n",
      "                        NATURAL_KEYS_PROP))\n",
      "                .required()\n",
      "                .build();\n",
      "        builder.describe(NATURAL_KEYS_PROP, NATURAL_KEYS_LABEL, NATURAL_KEYS_DESC)\n",
      "                .type(SnapType.TABLE)\n",
      "                .withEntry(naturalKeyProperty)\n",
      "                .required()\n",
      "                .add();\n",
      "        SnapProperty causeField = builder.describe(CAUSE_FIELD_PROP,\n",
      "                CAUSE_FIELDS_LABEL, CAUSE_FIELDS_DESC)\n",
      "                .type(SnapType.STRING)\n",
      "                .required()\n",
      "                .expression()\n",
      "                .withSuggestions(new ColumnNamesSuggestProvider(this, CAUSE_FIELD_PROP,\n",
      "                        CAUSE_FIELDS_PROP))\n",
      "                .build();\n",
      "        builder.describe(CAUSE_FIELDS_PROP, CAUSE_FIELDS_LABEL, CAUSE_FIELDS_DESC)\n",
      "                .type(SnapType.TABLE)\n",
      "                .withEntry(causeField)\n",
      "                .required()\n",
      "                .add();\n",
      "        SnapProperty meaningProp = builder.describe(MEANING_PROP, MEANING_LABEL, MEANING_DESC)\n",
      " <MID>\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 04:55:38,343 - DEBUG - Starting new HTTP connection (1): 127.0.0.1:8008\n",
      "2023-11-27 04:55:38,346 - DEBUG - http://127.0.0.1:8008 \"POST /v1/completions HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'comp-49stw55T2jff', 'object': 'text_completion', 'status': 'completed', 'created': 1701060926.2475886, 'uploaded': 1701060938.3415048, 'generated_tokens_n': 71, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'stop-eot', 'text': '       builder.describe(TABLE_COLUMN_LIST_PROP, TABLE_COLUMN_LIST_LABEL, TABLE_COLUMN_LIST_DESC)\\n                .type(SnapType.TABLE)\\n                .withEntry(columnNameProp)\\n                .withEntry(columnDataTypeProp)\\n <EOT>'}]}\n",
      "\n",
      " Inference output: \n",
      " \u001b[32m       builder.describe(TABLE_COLUMN_LIST_PROP, TABLE_COLUMN_LIST_LABEL, TABLE_COLUMN_LIST_DESC)\n",
      "                .type(SnapType.TABLE)\n",
      "                .withEntry(columnNameProp)\n",
      "                .withEntry(columnDataTypeProp)\n",
      " <EOT>\u001b[0m\n",
      "\n",
      " Label: \n",
      "         builder.describe(TABLE_COLUMN_LIST_PROP, TABLE_COLUMNS_LIST_LABEL, TABLE_COLUMNS_LIST_DESC)\n",
      "                .type(SnapType.TABLE)\n",
      "                .enableIf(COLUMN_TABLE_ENABLE_COND)\n",
      "                .withEntry(columnNameProp)\n",
      "                .withEntry(columnDataTypeProp)\n",
      "\n",
      "\n",
      " Prompt: \n",
      " \u001b[33m<PRE> /*\n",
      " * SnapLogic - Data Integration\n",
      " *\n",
      " * Copyright (C) 2022, SnapLogic, Inc.  All rights reserved.\n",
      " *\n",
      " * This program is licensed under the terms of\n",
      " * the SnapLogic Commercial Subscription agreement.\n",
      " *\n",
      " * \"SnapLogic\" is a trademark of SnapLogic, Inc.\n",
      " */\n",
      "package com.snaplogic.snaps.databricks;\n",
      "\n",
      "import com.snaplogic.snap.api.SnapDataException;\n",
      "import com.snaplogic.snap.api.sql.DatabaseAccount;\n",
      "import com.snaplogic.snap.api.sql.JdbcOperations;\n",
      "\n",
      "import java.sql.Connection;\n",
      "import java.sql.SQLException;\n",
      "import java.sql.Statement;\n",
      "\n",
      "import static com.snaplogic.snaps.databricks.Messages.ERR_GENERIC_EXCEPTION;\n",
      "import static com.snaplogic.snaps.databricks.Messages.ERR_GENERIC_RESOLUTION;\n",
      "\n",
      "/**\n",
      " * Jdbc connections holder.\n",
      " * Holds connection to share it between different services\n",
      " */\n",
      "public class JdbcConnectionHolder {\n",
      "\n",
      "    private final DatabaseAccount databricksAccount;\n",
      "    private final JdbcOperations jdbcOperations;\n",
      "\n",
      "    public JdbcConnectionHolder(DatabaseAccount databricksAccount, JdbcOperations jdbcOperations) {\n",
      "        this.databricksAccount = databricksAccount;\n",
      "        this.jdbcOperations = jdbcOperations;\n",
      "    }\n",
      "\n",
      "    public Connection establishConnection() {\n",
      "        return jdbcOperations.acquireConnection(databricksAccount);\n",
      "    }\n",
      "\n",
      "    public int executeUpdateSql(String sql) {\n",
      "        establishConnection();\n",
      "        try (Statement stmt = establishConnection().createStatement()) {\n",
      "            return stmt.executeUpdate(sql);\n",
      "        } catch (SQLException e) {\n",
      "            throw new SnapDataException(e, ERR_GENERIC_EXCEPTION)\n",
      "                    .withReason(e.getMessage())\n",
      "                    .withResolution(ERR_GENERIC_RESOLUTION);\n",
      " <SUF>        try (Statement stmt = establishConnection().createStatement()) {\n",
      "            stmt.execute(sql);\n",
      "        } catch (SQLException e) {\n",
      "            throw new SnapDataException(e, ERR_GENERIC_EXCEPTION)\n",
      "                    .withReason(e.getMessage())\n",
      "                    .withResolution(ERR_GENERIC_RESOLUTION);\n",
      "        }\n",
      "    }\n",
      "}\n",
      " <MID>\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 04:55:42,520 - DEBUG - Starting new HTTP connection (1): 127.0.0.1:8008\n",
      "2023-11-27 04:55:42,522 - DEBUG - http://127.0.0.1:8008 \"POST /v1/completions HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'comp-Am2CfdKQDhNi', 'object': 'text_completion', 'status': 'completed', 'created': 1701060938.3453043, 'uploaded': 1701060942.517956, 'generated_tokens_n': 25, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'stop-eot', 'text': '       }\\n    }\\n\\n    public void executeSql(String sql) {\\n        establishConnection();\\n <EOT>'}]}\n",
      "\n",
      " Inference output: \n",
      " \u001b[32m       }\n",
      "    }\n",
      "\n",
      "    public void executeSql(String sql) {\n",
      "        establishConnection();\n",
      " <EOT>\u001b[0m\n",
      "\n",
      " Label: \n",
      "         }\n",
      "    }\n",
      "\n",
      "    public void executeSql(String sql) {\n",
      "        establishConnection();\n",
      "\n",
      "\n",
      " Prompt: \n",
      " \u001b[33m<PRE>     protected String url;\n",
      "    protected String exportOrServiceURL;\n",
      "    protected List<Pair<String, ExpressionProperty>> queryParams;\n",
      "    protected boolean isBulkUpdate = false;\n",
      "    protected boolean isValidation = false;\n",
      "    protected boolean moreRequests = false;\n",
      "    protected boolean isAllEntities = false;\n",
      "    protected Map<String, Object> cursorMap = null;\n",
      "    protected boolean isEmptyResponsesAsSeparateDocuments;\n",
      "    @Inject\n",
      "    protected SnapObjectMapper snapObjectMapper;\n",
      "    @Inject\n",
      "    protected XmlUtils xmlUtils;\n",
      "    @Inject\n",
      "    protected ReltioAccount account;\n",
      "    @Inject\n",
      "    protected RestHttpClient restHttpClient;\n",
      "\n",
      "    protected enum ObjectTypeForAllRecords {\n",
      "        ENTITIES, RELATIONS\n",
      "    };\n",
      "\n",
      "    protected ObjectTypeForAllRecords found = null;\n",
      "\n",
      "    public ReltioSnapConnectorCommon(boolean isExecute, boolean isGetByCrosswalks) {\n",
      "        this.isExecute = isExecute;\n",
      "        this.isGetByCrosswalks = isGetByCrosswalks;\n",
      "    }\n",
      "\n",
      "    public ReltioSnapConnectorCommon() {\n",
      "        this(false, false);\n",
      "    }\n",
      "\n",
      "    private static Set<String> findKeysOfObject(Map<String, Object> mapObject, String rootKey)\n",
      "            throws SnapDataException {\n",
      "        logger.trace(\"In findKeysOfObject start\");\n",
      "        Set<String> fieldsSet = new HashSet<>();\n",
      "        for (Map.Entry<String, Object> m : mapObject.entrySet()) {\n",
      "            String key = m.getKey();\n",
      "            Object value = m.getValue();\n",
      "            Map<String, Object> jsout = null;\n",
      "            List jsArr = null;\n",
      "            try {\n",
      "                if (value instanceof Map) {\n",
      "                    fieldsSet.add(key);\n",
      "                    jsout = (Map<String, Object>) value;\n",
      "                    if (rootKey != null) {\n",
      "                        CollectionUtils.addAll(fieldsSet, findKeysOfObject(jsout, rootKey + \".\" + key).iterator());\n",
      "                    } else {\n",
      "                        CollectionUtils.addAll(fieldsSet, findKeysOfObject(jsout, key).iterator());\n",
      " <SUF>                    } else {\n",
      "                        findKeysOfArray(jsArr, key, fieldsSet);\n",
      "                    }\n",
      "                } else {\n",
      "                    fieldsSet.add((rootKey != null) ? (rootKey + \".\" + key) : (key));\n",
      "                }\n",
      "            } catch (Exception e) {\n",
      "                Throwable t = Throwables.getRootCause(e);\n",
      "                throw new SnapDataException(t, ERR_WHILE_PREPARING_JSON_OBJECT)\n",
      "                        .withReason(e.getMessage())\n",
      "                        .withResolution(ERROR_RESOLUTION);\n",
      "            }\n",
      "            logger.trace(\"In findKeysOfObject end\");\n",
      "        }\n",
      "\n",
      "        return fieldsSet;\n",
      "    }\n",
      "\n",
      "    private static void findKeysOfArray(List<Map<String, Object>> input, String rootKey,\n",
      "            Set<String> fieldsSet) {\n",
      "        if (input == null) {\n",
      "            return;\n",
      "        }\n",
      "        for (Object anInput : input) {\n",
      "            if (anInput instanceof Map) {\n",
      "                Map<String, Object> object = (Map<String, Object>) anInput;\n",
      "                fieldsSet.add(rootKey);\n",
      "                if (object != null) {\n",
      "                    CollectionUtils.addAll(fieldsSet, findKeysOfObject(object, rootKey).iterator());\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "\n",
      "    protected final void defineTenantProperty(PropertyBuilder propertyBuilder) {\n",
      "        propertyBuilder.describe(TENANT_PROP, TENANT_LABEL, TENANT_DESCRIPTION)\n",
      "                .expression()\n",
      "                .required()\n",
      "                .defaultValue(RELTIO_TENANT_URL_FORMAT)\n",
      "                .add();\n",
      "    }\n",
      "\n",
      "    protected void defineObjectProperty(PropertyBuilder propertyBuilder) {\n",
      "        propertyBuilder.describe(OBJECT, OBJECT_LABEL, RELTIO_OBJECT_DESC)\n",
      "                .expression()\n",
      "                .withSuggestions((suggestionBuilder, propertyValues) -> {\n",
      "                    String[] objectNames = getConfigData(propertyValues);\n",
      "                    suggestionBuilder.node(ReltioSnapConnectorMessages.OBJECT)\n",
      "                            .suggestions(objectNames);\n",
      "                }).required().add();\n",
      " <MID>\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 04:55:53,683 - DEBUG - Starting new HTTP connection (1): 127.0.0.1:8008\n",
      "2023-11-27 04:55:53,685 - DEBUG - http://127.0.0.1:8008 \"POST /v1/completions HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'comp-GWTKIRPM37ZE', 'object': 'text_completion', 'status': 'completed', 'created': 1701060942.5218859, 'uploaded': 1701060953.6807272, 'generated_tokens_n': 71, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'stop-eot', 'text': '                   }\\n                } else if (value instanceof List) {\\n                    fieldsSet.add(key);\\n                    jsArr = (List) value;\\n                    if (rootKey != null) {\\n                        findKeysOfArray(jsArr, rootKey + \".\" + key, fieldsSet);\\n <EOT>'}]}\n",
      "\n",
      " Inference output: \n",
      " \u001b[32m                   }\n",
      "                } else if (value instanceof List) {\n",
      "                    fieldsSet.add(key);\n",
      "                    jsArr = (List) value;\n",
      "                    if (rootKey != null) {\n",
      "                        findKeysOfArray(jsArr, rootKey + \".\" + key, fieldsSet);\n",
      " <EOT>\u001b[0m\n",
      "\n",
      " Label: \n",
      "                     }\n",
      "                } else if (value instanceof List) {\n",
      "                    jsArr = (List) value;\n",
      "                    if (rootKey != null) {\n",
      "                        findKeysOfArray(jsArr, rootKey + \".\" + key, fieldsSet);\n",
      "\n",
      "\n",
      " Prompt: \n",
      " \u001b[33m<PRE>      * getPropertyValues\n",
      "     *\n",
      "     * @return PropertyValues\n",
      "     */\n",
      "    public PropertyValues getPropertyValues() {\n",
      "        return propertyValues;\n",
      "    }\n",
      "\n",
      "    /**\n",
      "     * getServer\n",
      "     *\n",
      "     * @return server\n",
      "     */\n",
      "    public String getServer() {\n",
      "        String server = StringUtils.trim((String)\n",
      "                (propertyValues.getAsExpression(TableauAccount.SERVER)).eval(null));\n",
      "        // if server ends with '/' then we will chop it off as it would cause error while building\n",
      "        // connect url\n",
      "        if (server.endsWith(\"/\")) {\n",
      "            server = server.substring(0, server.length() - 1);\n",
      "        }\n",
      "        return server;\n",
      "    }\n",
      "\n",
      "    /**\n",
      "     * getServerVersion\n",
      "     *\n",
      "     * @return server version\n",
      "     */\n",
      "    public String getServerVersion() {\n",
      "        return StringUtils.trim((String) propertyValues.get(SERVER_VERSION));\n",
      "    }\n",
      "\n",
      "    /**\n",
      "     * getOtherServerAPIVersion\n",
      "     *\n",
      "     * @return\n",
      "     */\n",
      "    public String getOtherServerAPIVersion() {\n",
      "        return StringUtils.trim((String)\n",
      "                (propertyValues.getAsExpression(OTHER_SERVER_API_VERSION)).eval(null));\n",
      "    }\n",
      "\n",
      "    /**\n",
      "     * getXmlSchema\n",
      "     *\n",
      "     * @return XSD to be used for REST calls\n",
      "     */\n",
      "    public String getXmlSchema() {\n",
      "        return propertyValues.getAsExpression(XML_SCHEMA).eval(null);\n",
      " <SUF>     *\n",
      "     * @param serverVersion\n",
      "     * @return respective API version\n",
      "     */\n",
      "    private String getAPIVersion(String serverVersion) {\n",
      "        return APIUtils.SERVER_TO_SCHEMA_MAP.get(serverVersion);\n",
      "    }\n",
      "\n",
      "    /**\n",
      "     * getSite\n",
      "     *\n",
      "     * @return site\n",
      "     */\n",
      "    public String getSite() {\n",
      "        return StringUtils.trim((String) propertyValues.get(TableauAccount.SITE));\n",
      "    }\n",
      "\n",
      "    /**\n",
      "     * getUserId\n",
      "     *\n",
      "     * @return user Id\n",
      "     */\n",
      "    public String getUserId() {\n",
      "        return userId;\n",
      "    }\n",
      "\n",
      "    /**\n",
      "     * getSiteId\n",
      "     *\n",
      "     * @return site Id\n",
      "     */\n",
      "    public String getSiteId() {\n",
      "        return siteId;\n",
      "    }\n",
      "\n",
      "    /**\n",
      "     * getErrorMap\n",
      "     *\n",
      "     * @return map of errors\n",
      "     */\n",
      "    public Map<String, Object> getErrorMap() {\n",
      "        return errorMap;\n",
      "    }\n",
      "\n",
      "    @Override\n",
      "    public void configure(PropertyValues propertyValues) {\n",
      "        this.propertyValues = propertyValues;\n",
      "        if (StringUtils.isBlank(getSchema(getServerVersion()))) {\n",
      "            throw new ConfigurationException(Messages.ERR_INVALID_CONFIGURATION_MSG)\n",
      "                    .withReason(Messages.ERR_XML_MISSING_REASON)\n",
      " <MID>\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 04:56:08,334 - DEBUG - Starting new HTTP connection (1): 127.0.0.1:8008\n",
      "2023-11-27 04:56:08,336 - DEBUG - http://127.0.0.1:8008 \"POST /v1/completions HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'comp-RPTnttwihXPi', 'object': 'text_completion', 'status': 'completed', 'created': 1701060953.684675, 'uploaded': 1701060968.3313718, 'generated_tokens_n': 90, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'stop-eot', 'text': '   }\\n\\n    /**\\n     * getSchema\\n     *\\n     * @param serverVersion\\n     * @return XSD to be used for REST calls\\n     */\\n    public String getSchema(String serverVersion) {\\n        return getAPIVersion(serverVersion) == null ? getXmlSchema() : getAPIVersion(serverVersion);\\n    }\\n\\n    /**\\n     * getAPIVersion\\n <EOT>'}]}\n",
      "\n",
      " Inference output: \n",
      " \u001b[32m   }\n",
      "\n",
      "    /**\n",
      "     * getSchema\n",
      "     *\n",
      "     * @param serverVersion\n",
      "     * @return XSD to be used for REST calls\n",
      "     */\n",
      "    public String getSchema(String serverVersion) {\n",
      "        return getAPIVersion(serverVersion) == null ? getXmlSchema() : getAPIVersion(serverVersion);\n",
      "    }\n",
      "\n",
      "    /**\n",
      "     * getAPIVersion\n",
      " <EOT>\u001b[0m\n",
      "\n",
      " Label: \n",
      "     }\n",
      "\n",
      "    /**\n",
      "     * Gives the API version to be used for the provided server version\n",
      "     * http://onlinehelp.tableau.com/current/api/rest_api/en-us/REST/rest_api_concepts_schema.htm\n",
      "\n",
      "\n",
      " Prompt: \n",
      " \u001b[33m<PRE> package com.snaplogic.snap.api.sql;\n",
      "\n",
      "import com.snaplogic.common.services.SnapDatabaseCursor;\n",
      "import com.snaplogic.snap.api.Document;\n",
      "import com.snaplogic.snap.api.DocumentUtility;\n",
      "import com.snaplogic.snap.api.ErrorViews;\n",
      "import com.snaplogic.snap.api.OutputViews;\n",
      "import com.snaplogic.snap.api.sql.quotation.QuotationHandler;\n",
      "\n",
      "import org.apache.commons.text.WordUtils;\n",
      "import org.jooq.SQLDialect;\n",
      "import org.slf4j.Logger;\n",
      "\n",
      "import java.sql.BatchUpdateException;\n",
      "import java.sql.Connection;\n",
      "import java.sql.SQLException;\n",
      "import java.util.ArrayList;\n",
      "import java.util.List;\n",
      "import java.util.Map;\n",
      "import java.util.UUID;\n",
      "\n",
      "import net.jodah.failsafe.ExecutionContext;\n",
      "import net.jodah.failsafe.RetryPolicy;\n",
      "\n",
      "/**\n",
      " * JDBC operations to execute various SQL statements.\n",
      " */\n",
      "public interface JdbcOperations {\n",
      "    /**\n",
      "     * Defines the action for duplicate keys.\n",
      "     */\n",
      "    enum DuplicateKeyAction {\n",
      "        FAIL, IGNORE, UPDATE;\n",
      "\n",
      "        @Override\n",
      "        public String toString() {\n",
      "            return WordUtils.capitalize(name().toLowerCase());\n",
      "        }\n",
      "    }\n",
      "\n",
      "    String MYSQL = \"MySQL\";\n",
      "    String ORACLE = \"Oracle\";\n",
      "    String SQLSERVER = \"SQL Server\";\n",
      "    String DB2 = \"DB2\";\n",
      "    String GENERIC = \"Generic\";\n",
      "    String REDSHIFT = \"Redshift\";\n",
      "    String POSTGRES = \"Postgres\";\n",
      "    String VERTICA = \"Vertica\";\n",
      "    String SAPHANA = \"SAPHana\";\n",
      "    String NETEZZA = \"Netezza\";\n",
      " <SUF>    String SQLMX = \"SQLMX\";\n",
      "    String SPARKSQL = \"Spark SQL\";\n",
      "    String SPARKSQL_NO_SPACE = \"SparkSQL\";\n",
      "    String AZURE_SYNAPSE = \"Azure Synapse\";\n",
      "    String DATABRICKS_LAKEHOUSE_PLATFORM = \"Databricks Lakehouse Platform\";\n",
      "    String BIGQUERY = \"BigQuery\";\n",
      "    String AWS_ATHENA = \"AWS Athena\";\n",
      "    String AWS_DOT_ATHENA = \"AWS.Athena\";\n",
      "    String[] AWS_ATHENA_ALL_NAMES = new String[] {\n",
      "            AWS_ATHENA,\n",
      "            AWS_DOT_ATHENA\n",
      "    };\n",
      "    String NETSUITE = \"Netsuite\";\n",
      "    String OPEN_ACCESS = \"OpenAccess\";\n",
      "\n",
      "    /**\n",
      "     * Retrieves a connection to the database if needed.\n",
      "     *\n",
      "     * @param account database account\n",
      "     * @return connection to the database\n",
      "     */\n",
      "    Connection acquireConnection(final DatabaseAccount account);\n",
      "\n",
      "    /**\n",
      "     * Executes a sql query and returns the result wrapped in a {@link SnapDatabaseCursor}.\n",
      "     *\n",
      "     * @param query      sql query\n",
      "     * @param bindValues values to bind in the query\n",
      "     * @param account    database account\n",
      "     * @param maxRetries Maximum number of times to retry this operation\n",
      "     * @param retryInterval\n",
      "     * @return snap database cursor\n",
      "     */\n",
      "    DatabaseCursor executeQuery(String query, List<Object> bindValues, DatabaseAccount account,\n",
      "                                int maxRetries, long retryInterval) throws SQLException;\n",
      "\n",
      "    /**\n",
      "     * Executes a sql query and returns the result wrapped in a {@link SnapDatabaseCursor}.\n",
      "     *\n",
      "     * @param query      sql query\n",
      "     * @param bindValues values to bind in the query\n",
      "     * @param account    database account\n",
      "     * @param maxRetries Maximum number of times to retry this operation\n",
      "     * @param retryInterval\n",
      "     * @param elt       Tells whether ELT mode is enabled or not.\n",
      "     * @return snap database cursor\n",
      "     */\n",
      "    DatabaseCursor executeQuery(String query, List<Object> bindValues, DatabaseAccount account,\n",
      "                                int maxRetries, long retryInterval,\n",
      "                                boolean elt) throws SQLException;\n",
      " <MID>\u001b[0m\n",
      "{'id': 'comp-bLqYJG9XLMuD', 'object': 'text_completion', 'status': 'completed', 'created': 1701060968.3358247, 'uploaded': 1701061009.172455, 'generated_tokens_n': 255, 'model': 'codellama/7b', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': 'length', 'text': '   String SNOWFLAKE = \"Snowflake\";\\n    String SNOWFLAKE_PLATFORM = \"Snowflake Platform\";\\n    String SNOWFLAKE_PLATFORM_NO_SPACE = \"SnowflakePlatform\";\\n    String SNOWFLAKE_PLATFORM_ALL_NAMES = new String[] {\\n            SNOWFLAKE_PLATFORM,\\n            SNOWFLAKE_PLATFORM_NO_SPACE\\n    };\\n    String SNOWFLAKE_PLATFORM_ALL_NAMES_WITH_SPACE = new String[] {\\n            SNOWFLAKE_PLATFORM,\\n            SNOWFLAKE_PLATFORM_NO_SPACE,\\n            SNOWFLAKE_PLATFORM_NO_SPACE + \" \" + SNOWFLAKE_PLATFORM\\n    };\\n    String SNOWFLAKE_PLATFORM_ALL_NAMES_WITH_SPACE_AND_DOT = new String[] {\\n            SNOWFLAKE_PLATFORM,\\n            SNOWFLA'}]}\n",
      "\n",
      " Inference output: \n",
      " \u001b[32m   String SNOWFLAKE = \"Snowflake\";\n",
      "    String SNOWFLAKE_PLATFORM = \"Snowflake Platform\";\n",
      "    String SNOWFLAKE_PLATFORM_NO_SPACE = \"SnowflakePlatform\";\n",
      "    String SNOWFLAKE_PLATFORM_ALL_NAMES = new String[] {\n",
      "            SNOWFLAKE_PLATFORM,\n",
      "            SNOWFLAKE_PLATFORM_NO_SPACE\n",
      "    };\n",
      "    String SNOWFLAKE_PLATFORM_ALL_NAMES_WITH_SPACE = new String[] {\n",
      "            SNOWFLAKE_PLATFORM,\n",
      "            SNOWFLAKE_PLATFORM_NO_SPACE,\n",
      "            SNOWFLAKE_PLATFORM_NO_SPACE + \" \" + SNOWFLAKE_PLATFORM\n",
      "    };\n",
      "    String SNOWFLAKE_PLATFORM_ALL_NAMES_WITH_SPACE_AND_DOT = new String[] {\n",
      "            SNOWFLAKE_PLATFORM,\n",
      "            SNOWFLA\u001b[0m\n",
      "\n",
      " Label: \n",
      "     String CASSANDRA = \"Cassandra\";\n",
      "    String SNOWFLAKE = \"Snowflake\";\n",
      "    String TERADATA = \"Teradata\";\n",
      "    String HIVE = \"Apache Hive\";\n",
      "    String DERBY = \"Apache Derby\";\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate_responses(output_directory = \"./example_prompts/\",\n",
    "#                        prompts_path = \"./example_prompts/\",\n",
    "#                        model = MODEL,\n",
    "#                        temperature = TEMPERATURE,\n",
    "#                        top_p = TOP_P,\n",
    "#                        times = TIMES,\n",
    "#                        max_tokens = MAX_TOKENS)\n",
    "\n",
    "generate_responses(output_directory = \"./example_prompts/\",\n",
    "                       prompts_path = \"./example_prompts/\",\n",
    "                       model = MODEL,\n",
    "                       temperature = TEMPERATURE,\n",
    "                       top_p = .6,\n",
    "                       times = 3,\n",
    "                       logprobs = True,\n",
    "                       max_tokens = MAX_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69953b16",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect lines input .csv file\n",
    "\n",
    "# n = 100\n",
    "\n",
    "# snap_lines_prompts_df = pd.read_csv(\"../data/prompts/lines_df.csv\")\n",
    "# #snap\n",
    "# print(len(snap_lines_prompts_df))\n",
    "# lines_nth_row = snap_lines_prompts_df.iloc[n]\n",
    "\n",
    "# print(lines_nth_row)\n",
    "\n",
    "\n",
    "# for column_name, cell_content in lines_nth_row.items():\n",
    "#     print(f\"Column: {column_name}\\nContent: {cell_content}\\n{'-'*50}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231e241e-93ba-40df-a7b2-e9816fcdbdc9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect methods input .csv file\n",
    "\n",
    "# n = 0\n",
    "\n",
    "# snap_methods_prompts_df = pd.read_csv(\"../data/methods_df_10_30.csv\")\n",
    "\n",
    "# #how many prompts?\n",
    "# print(len(snap_methods_prompts_df))\n",
    "\n",
    "# #inspect a line\n",
    "# lines_nth_row = snap_methods_prompts_df.iloc[n]\n",
    "# print(lines_nth_row)\n",
    "\n",
    "\n",
    "# for column_name, cell_content in lines_nth_row.items():\n",
    "#     print(f\"Column: {column_name}\\nContent: {cell_content}\\n{'-'*50}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c3824-5af7-4da1-beb2-759060d8ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up initial .csvL 1) Update column headers 2) drop NaN columnns\n",
    "# snap_methods_prompts_df.rename(columns={\"0\": \"path\", \"1\":\"prompt\", \"2\":\"label\", \"3\":\"start_line\", \"4\":\"end_line\"}, inplace=True)\n",
    "# snap_methods_prompts_df.drop(columns=['5', '6', '7', '8'], inplace=True)\n",
    "# snap_methods_prompts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d450ff82",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# orig = snap_methods_prompts_df.iloc[0][\"prompt\"]\n",
    "# print_me = termcolor.colored(orig, \"yellow\")\n",
    "# print(\"\\n\", \"Prompt:\",\"\\n\",print_me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inspect methods .csv\n",
    "# snap_methods_prompts_df = pd.read_csv(\"methods_df_10_30.csv\")\n",
    "# methods_first_row = snap_prompts_df.iloc[0]\n",
    "\n",
    "# print(first_row)\n",
    "\n",
    "\n",
    "# for column_name, cell_content in first_row.items():\n",
    "#     print(f\"Column: {column_name}\\nContent: {cell_content}\\n{'-'*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14cb3fd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the prompts through the model storing in a list to add back to our original dataframe\n",
    "\n",
    "# completion_output = []\n",
    "\n",
    "# for i in range(0,len(snap_methods_prompts_df)):\n",
    "#     orig = snap_methods_prompts_df.iloc[i][\"prompt\"]\n",
    "#     #print_me = termcolor.colored(orig[:-1], \"yellow\")\n",
    "#     print_me = termcolor.colored(orig, \"yellow\") # line above is stripping '>' from <MID> token\n",
    "\n",
    "#     print(\"\\n\", \"Prompt:\",\"\\n\",print_me)\n",
    "\n",
    "#     # run inference with prompt\n",
    "#     t = run_completion_call(orig)\n",
    "\n",
    "#     # save response\n",
    "#     uncut = t\n",
    "\n",
    "#     # process response\n",
    "#     lines = t.split(\"\\n\")\n",
    "#     filtered = [x for x in lines if x.startswith(\" \") or x.strip() == \"\"]\n",
    "#     t = \"\\n\".join(filtered)\n",
    "\n",
    "#     # add response to list\n",
    "#     completion_output.append(t)\n",
    "    \n",
    "    \n",
    "#     #assert uncut.startswith(t)\n",
    "#     # Print response together with prompt and label\n",
    "#     print_response = termcolor.colored(t, \"green\") + \" \" + termcolor.colored(uncut[len(t):], attrs=[\"dark\"])\n",
    "#     print(print_response)\n",
    "#     print(\"\\n\", \"Label:\",\"\\n\", snap_methods_prompts_df.iloc[i][\"label\"])\n",
    "\n",
    "# # Add generated output back to original DataFrame\n",
    "# snap_methods_prompts_df['Completion'] = completion_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad20b6-5990-4527-88e3-9d041f8327ae",
   "metadata": {},
   "outputs": [],
   "source": [
    " # snap_methods_prompts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c7bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect lines .csv post inference\n",
    "# snap_lines_prompts_df['Completion'] = completion_output\n",
    "# lines_first_row = snap_lines_prompts_df.iloc[0]\n",
    "\n",
    "# print(lines_first_row)\n",
    "\n",
    "\n",
    "# for column_name, cell_content in lines_first_row.items():\n",
    "#     print(f\"Column: {column_name}\\nContent: {cell_content}\\n{'-'*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba08fd19-05bc-4253-bcf8-a117d5d84eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write inference output to .csv\n",
    "# snap_lines_prompts_df.to_csv('\"../data/output/20231109_lora-20231107-201630_finetune_inference_output.csv', index=False)\n",
    "# Write hyperparameters to a JSON file\n",
    "# with open('../data/output/20231107_lora-20231107-201630_metadata.json', 'w') as meta_file:\n",
    "#     json.dump(metadata, meta_file, indent=4)\n",
    "\n",
    "# # Write inference output to .csv\n",
    "# snap_methods_prompts_df.to_csv('../data/output/20231112_codellama7B_pretrained_inference_output.csv', index=False)\n",
    "\n",
    "# # Write hyperparameters to a JSON file\n",
    "# with open('../data/output/20231112_codellama7B_pretrained_metadata.json', 'w') as meta_file:\n",
    "#     json.dump(metadata, meta_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b50461-b603-402d-a3af-76cc174d8ac4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MPI Variant: Run /completions endpoint on prompts, test code for generate_responses.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "083cac9f-01ac-4ec0-9ed8-52648dd2a128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys, termcolor, subprocess, json, time, random\n",
    "from copy import deepcopy\n",
    "from mpi4py import MPI\n",
    "from human_eval.data import write_jsonl, read_problems\n",
    "from human_eval.data import read_problems\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from config import config_dict, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "229215c4-ce7d-4b88-a75f-045add7814a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global config, can be overridden via function arguments to \n",
    "# evaluation_framework function.\n",
    "PROMPTS_PATH = config_dict['prompt_directory']\n",
    "GENERATED_RESPONSES_DIRECTORY = config_dict['generated_responses_directory']\n",
    "MODEL = config_dict['inference_model']\n",
    "TEMPERATURE = config_dict['inference_temperature']\n",
    "TOP_P = config_dict['inference_top_p']\n",
    "TIMES = config_dict['inference_times']\n",
    "MAX_TOKENS = config_dict['inference_max_tokens']\n",
    "INFERENCE_ENDPOINT = config_dict['inference_endpoint']\n",
    "\n",
    "metadata = {\n",
    "    'MODEL': MODEL,\n",
    "    'TEMPERATURE': TEMPERATURE,\n",
    "    'TOP_P': TOP_P,\n",
    "    'TIMES': TIMES,\n",
    "    'MAX_TOKENS': MAX_TOKENS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f75eb9-9a27-42a7-a13c-dd2534b59d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions - MPI variant, allows multiple GPUs to be used for inference\n",
    "def run_completion_call(src_txt,\n",
    "                        model,\n",
    "                        max_tokens,\n",
    "                        top_p,\n",
    "                        temperature):\n",
    "    \"\"\" Execute a single call to refact /v1/completions API\n",
    "\n",
    "    Keyword arguments:\n",
    "    src_txt -- prompt to be fed to refact hosted model. The Completion\n",
    "    API assumes that prompt is a completion-oriented prompt, typically\n",
    "    of the form <PRE> ... text ... <SUF> .. text .. <MID>. It is the \n",
    "    model's task to \"fill in the missing text between <PRE> and <SUF>.\n",
    "    \"\"\"\n",
    "    res = requests.post(f\"{INFERENCE_ENDPOINT}/v1/completions\", json={\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"stream\": False,\n",
    "        \"echo\": True,\n",
    "        \"top_p\": top_p,\n",
    "        \"temperature\": temperature,\n",
    "        \"prompt\": src_txt,\n",
    "        \"stop\": [\"\\n\\n\\n\"],\n",
    "    })\n",
    "    res.raise_for_status()\n",
    "    j = res.json()\n",
    "    # print(j)\n",
    "    return j[\"choices\"][0][\"text\"]\n",
    "\n",
    "\n",
    "def generate_responses(output_directory = GENERATED_RESPONSES_DIRECTORY,\n",
    "                       prompts_path = PROMPTS_PATH,\n",
    "                       model = MODEL,\n",
    "                       temperature = TEMPERATURE,\n",
    "                       top_p = TOP_P,\n",
    "                       times = TIMES,\n",
    "                       max_tokens = MAX_TOKENS):\n",
    "    \"\"\" Given an output directory, generate responses via inference\n",
    "    and writes responses to the output directory.\n",
    "\n",
    "    Keyword arguments:\n",
    "    output_directory -- directory to write responses, default specified\n",
    "                        in config.py\n",
    "    prompts_path -- directory to find prompt files. default specified\n",
    "                    in config.py.\n",
    "    prompt_file -- alternative, specify a specific prompt file. If\n",
    "                   prompt file is specified, the batch directory\n",
    "                   approach is overriden. No default.\n",
    "    model -- specify model to be run format examples: 'codellama' or\n",
    "             'codellama/7b/lora-20231107-201630' in the case of a fine\n",
    "             tuned model. Default specified in config.py.\n",
    "    temperature -- temperature for chosen model. Default specified in \n",
    "                   config.py\n",
    "    top_p -- Top P cutoff for token selection. Default specified in \n",
    "             config.py\n",
    "    times -- Number of inference calls for the prompt, supporting\n",
    "             sampling of outputs. Default specified in config.py\n",
    "    max_tokens - Maximum number of tokens to be generated. Default\n",
    "                 specified in config.py.\n",
    "    \"\"\"\n",
    "    # ToDo: Add in ability to specify a specific prompts file and output directory for testing\n",
    "    logger.info(\"Generate responses\")\n",
    "\n",
    "    # Process all prompt files in prompts/ directory\n",
    "    for file in os.listdir(prompts_path):\n",
    "        if file != 'skipped_files.csv':\n",
    "            file_path = os.path.join(prompts_path, file)\n",
    "            # Prompt dataframe. Columns are expected to be labeled\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Loop over prompts dataframe, run inference to complete infilling\n",
    "            # After each file is complete, write new .csv with inference output\n",
    "            # as new column. Additionally write corresponding metadata file.\n",
    "            completion_output = []\n",
    "            for i in range(0,len(df)):\n",
    "             \n",
    "                # prompt from input dataframe\n",
    "                prompt = df.iloc[i][\"prompt\"]\n",
    "                print_prompt = termcolor.colored(prompt, \"yellow\") \n",
    "\n",
    "                print(\"\\n\", \"Prompt:\",\"\\n\",print_prompt)\n",
    "\n",
    "                # run inference with prompt\n",
    "                t = run_completion_call(prompt,\n",
    "                                        model,\n",
    "                                        max_tokens,\n",
    "                                        top_p,\n",
    "                                        temperature)\n",
    "\n",
    "                # add response to list\n",
    "                completion_output.append(t)\n",
    "\n",
    "                # Print response together with prompt and label\n",
    "            \n",
    "                print_response = termcolor.colored(t, \"green\")\n",
    "\n",
    "                print(\"\\n\", \"Inference output:\", \"\\n\", print_response)\n",
    "                print(\"\\n\", \"Label:\",\"\\n\", df.iloc[i][\"label\"])\n",
    "\n",
    "            # Add generated output back to original DataFrame\n",
    "            df['Completion'] = completion_output\n",
    "\n",
    "            # # Write inference output to .csv\n",
    "            # timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "            # inference_output_filename = f\"{output_directory}{timestamp}_{model.replace('/', '-')}_output.csv\"\n",
    "            # df.to_csv(inference_output_filename, index=False)\n",
    "\n",
    "            # # Write metadata to a JSON file\n",
    "            # metadata_output_filename = f\"{output_directory}{timestamp}_{model.replace('/', '-')}_metadata.json\"\n",
    "            # with open(metadata_output_filename, 'w') as meta_file:\n",
    "            #     json.dump(metadata, meta_file, indent=4)\n",
    "\n",
    "            try:\n",
    "                # Write inference output to .csv\n",
    "                timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "                model_filename = model.replace('/', '-')  # Replace forward slashes in model name\n",
    "                inference_output_filename = os.path.join(output_directory, f\"{timestamp}_{model_filename}_output.csv\")\n",
    "            \n",
    "                # Check if the directory exists, create if not\n",
    "                if not os.path.exists(output_directory):\n",
    "                    os.makedirs(output_directory)\n",
    "            \n",
    "                df.to_csv(inference_output_filename, index=False)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while writing the CSV file: {e}\")\n",
    "            \n",
    "            try:\n",
    "                # Write metadata to a JSON file\n",
    "                metadata_output_filename = os.path.join(output_directory, f\"{timestamp}_{model_filename}_metadata.json\")\n",
    "                \n",
    "                with open(metadata_output_filename, 'w') as meta_file:\n",
    "                    json.dump(metadata, meta_file, indent=4)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while writing the JSON file: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2fb3c6",
   "metadata": {},
   "source": [
    "## Run directly against model (this doesn't work yet at all and seems harder. Started by Adam, minimal changes by Jeremiah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487e3fd-f2f5-43f6-98fc-2f5334236c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77651aed-de2d-48a7-aab9-56ed89b2f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c3a5fe-4d23-479a-93cd-f9588a4cfc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class TheModelClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d229b90d-a3f1-4770-83d5-83aeb270085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeLlama7B(nn.Module):\n",
    "    def __init__(self, ...):  # Define the model's architecture parameters\n",
    "        super(CodeLlama7B, self).__init__()\n",
    "        # Define the layers and components of the model\n",
    "\n",
    "    def forward(self, ...):  # Define the forward pass\n",
    "        # Implement the forward pass logic\n",
    "\n",
    "# Create an instance of the model\n",
    "model = CodeLlama7B(...parameters...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda5541-5849-4e18-83b3-f85ee515a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model weights from the .pt file\n",
    "model_weights = torch.load(\"path/to/your/fine_tuned_model.pt\")\n",
    "\n",
    "# Load the state dictionary into your model\n",
    "model.load_state_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01778655-e5af-4c8e-afa6-b4e03c742621",
   "metadata": {},
   "outputs": [],
   "source": [
    " model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb4fae5-94c4-4b9a-9b71-d427bdceeabc",
   "metadata": {},
   "source": [
    "# Loading Model For Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59fe3e-0805-4bd7-b14f-c860c9f0a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c3f98a-4f29-4a54-9960-bedf8921d5eb",
   "metadata": {},
   "source": [
    "# Load Entire Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099eb034-acd7-4ecd-a0d7-f8870c64da05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49434bfd-20b7-4933-b2e4-dc3cffe7530f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model class must be defined somewhere\n",
    "model = torch.load('/home/ubuntu/.refact/perm-storage/loras/lora-20231026-161421/checkpoints/iter0070-testloss0.833/mp_rank_00_model_states.pt')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a49b10-cb51-4397-a5ee-b21ecb53f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e480e0cb-2ec4-414d-be2a-b854f8cbf312",
   "metadata": {},
   "source": [
    "# Load Model In TorchScript Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5069db-88fd-4ddc-9495-98fcf91b67f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load('/home/ubuntu/.refact/perm-storage/loras/lora-20231026-161421/checkpoints/iter0070-testloss0.833/mp_rank_00_model_states.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9313af-c37f-43b7-88d2-3dda16d00a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load('../.refact/perm-storage/loras/lora-20231002-231436/checkpoints/iter0750-testloss0.353/mp_rank_00_model_states.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26faeaae-b0d0-4eab-aab3-25d01d2b2fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
