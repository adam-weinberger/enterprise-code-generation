{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script analyzes the results of the evaluated responses. It computes the following metrics:<br>\n",
    "successful build rate: percentage of additional error count == 0<br>\n",
    "pass@1 rate: percentage of additional_failure_count == 0<br>\n",
    "CodeBLEU: average CodeBLEU score<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from scipy import stats\n",
    "\n",
    "import javalang\n",
    "\n",
    "from config import config_dict, logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_of_error(p_hat, n, confidence_level=0.95):\n",
    "  \"\"\"Calculates the margin of error for a proportion.\n",
    "\n",
    "  Args:\n",
    "    p_hat: The sample proportion.\n",
    "    n: The sample size.\n",
    "    confidence_level: The confidence level.\n",
    "\n",
    "  Returns:\n",
    "    The margin of error.\n",
    "  \"\"\"\n",
    "\n",
    "  z = stats.norm.ppf(1 - (confidence_level / 2))\n",
    "  se = np.sqrt(p_hat * (1 - p_hat) / n)\n",
    "  return z * se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens_in_label(label):\n",
    "    label = str(label)\n",
    "    label = label.replace('<EOT>', '')\n",
    "    try:\n",
    "        return len(list(javalang.tokenizer.tokenize(label)))\n",
    "    except:\n",
    "        return len(re.split(',| |_|-|=|\\.|\\+|\\*', label))\n",
    "\n",
    "def analyze_results_file(results_df, base_modules=False):\n",
    "    logger.info(\"Analyzing results\")\n",
    "\n",
    "    successful_build_rate = (results_df['pass'] == 0).sum() / len(results_df)\n",
    "    successful_build_rate_moe = margin_of_error(successful_build_rate, len(results_df))\n",
    "\n",
    "    no_error_rate = ((results_df['pass'] == 0) & (results_df['error_count'] == 0)).sum() / len(results_df)\n",
    "    no_error_rate_moe = margin_of_error(no_error_rate, len(results_df))\n",
    "\n",
    "    pass_at_1_rate = ((results_df['pass'] == 0) & (results_df['failure_count'] == 0)).sum() / len(results_df)\n",
    "    pass_at_1_rate_moe = margin_of_error(pass_at_1_rate, len(results_df))\n",
    "\n",
    "\n",
    "    results_dict = {}\n",
    "    columns_to_average = ['ngram_match_score', 'weighted_ngram_match_score', 'syntax_match_score', 'dataflow_match_score', 'label_token_count', 'completion_token_count']\n",
    "\n",
    "    if base_modules:\n",
    "        average_code_bleu = 1\n",
    "        average_code_bleu_moe = 0\n",
    "        \n",
    "        for column in columns_to_average:\n",
    "            results_dict[f'average_{column}'] = np.nan\n",
    "\n",
    "    else:\n",
    "        average_code_bleu = results_df['codebleu'].mean()\n",
    "        average_code_bleu_moe = results_df['codebleu'].std() #  is this how you calculate the standard error for a bounded continuous variable?\n",
    "        results_df['label_token_count'] = results_df['label'].apply(count_tokens_in_label)\n",
    "        results_df['completion_token_count'] = results_df['completion'].apply(count_tokens_in_label)\n",
    "        \n",
    "        for column in columns_to_average:\n",
    "            results_dict[f'average_{column}'] = results_df[column].mean()\n",
    "\n",
    "    results_dict['successful_build_rate'] = successful_build_rate\n",
    "    results_dict['successful_build_rate_moe'] = successful_build_rate_moe\n",
    "    results_dict['no_error_rate'] = no_error_rate\n",
    "    results_dict['no_error_rate_moe'] = no_error_rate_moe\n",
    "    results_dict['pass_at_1_rate'] = pass_at_1_rate\n",
    "    results_dict['pass_at_1_rate_moe'] = pass_at_1_rate_moe\n",
    "    results_dict['average_code_bleu'] = average_code_bleu\n",
    "    results_dict['average_code_bleu_moe'] = average_code_bleu_moe\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 17:00:24,447 - INFO - ../data/run_20231127_170530/evaluated_responses/base_module_build_results_237c7f40.json\n",
      "2023-12-09 17:00:24,468 - INFO - Analyzing results\n",
      "2023-12-09 17:00:24,471 - INFO - codellama-7b_tokens_output.csv\n",
      "2023-12-09 17:00:24,530 - INFO - Analyzing results\n",
      "2023-12-09 17:00:24,703 - INFO - codellama-7b_lines_output.csv\n",
      "2023-12-09 17:00:24,753 - INFO - Analyzing results\n",
      "2023-12-09 17:00:24,915 - INFO - codellama-7b_methods_output.csv\n",
      "2023-12-09 17:00:24,959 - INFO - Analyzing results\n",
      "2023-12-09 17:00:25,374 - INFO - 20231202_lines_codellama-7b-lora-20231107-201630_output.csv\n",
      "2023-12-09 17:00:25,424 - INFO - Analyzing results\n",
      "2023-12-09 17:00:25,637 - INFO - 20231202_methods_codellama-7b-lora-20231107-201630_output.csv\n",
      "2023-12-09 17:00:25,687 - INFO - Analyzing results\n",
      "2023-12-09 17:00:26,106 - INFO - 20231202_tokens_codellama-7b-lora-20231107-201630_output.csv\n",
      "2023-12-09 17:00:26,152 - INFO - Analyzing results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_ngram_match_score</th>\n",
       "      <th>average_weighted_ngram_match_score</th>\n",
       "      <th>average_syntax_match_score</th>\n",
       "      <th>average_dataflow_match_score</th>\n",
       "      <th>average_label_token_count</th>\n",
       "      <th>average_completion_token_count</th>\n",
       "      <th>successful_build_rate</th>\n",
       "      <th>successful_build_rate_moe</th>\n",
       "      <th>no_error_rate</th>\n",
       "      <th>no_error_rate_moe</th>\n",
       "      <th>pass_at_1_rate</th>\n",
       "      <th>pass_at_1_rate_moe</th>\n",
       "      <th>average_code_bleu</th>\n",
       "      <th>average_code_bleu_moe</th>\n",
       "      <th>prompt_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20231202_lines_codellama-7b-lora-20231107-201630_output</th>\n",
       "      <td>0.338706</td>\n",
       "      <td>0.607381</td>\n",
       "      <td>0.659051</td>\n",
       "      <td>0.316521</td>\n",
       "      <td>12.138</td>\n",
       "      <td>72.379</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.638087</td>\n",
       "      <td>0.238234</td>\n",
       "      <td>lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20231202_methods_codellama-7b-lora-20231107-201630_output</th>\n",
       "      <td>0.226282</td>\n",
       "      <td>0.490709</td>\n",
       "      <td>0.524821</td>\n",
       "      <td>0.315732</td>\n",
       "      <td>68.443</td>\n",
       "      <td>103.227</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.00094</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.505914</td>\n",
       "      <td>0.245222</td>\n",
       "      <td>methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20231202_tokens_codellama-7b-lora-20231107-201630_output</th>\n",
       "      <td>0.041936</td>\n",
       "      <td>0.197008</td>\n",
       "      <td>0.125959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.001</td>\n",
       "      <td>79.894</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.341226</td>\n",
       "      <td>0.069991</td>\n",
       "      <td>tokens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_modules</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codellama-7b_lines_output</th>\n",
       "      <td>0.398411</td>\n",
       "      <td>0.578653</td>\n",
       "      <td>0.666216</td>\n",
       "      <td>0.298311</td>\n",
       "      <td>12.138</td>\n",
       "      <td>48.021</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.648531</td>\n",
       "      <td>0.249855</td>\n",
       "      <td>lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codellama-7b_methods_output</th>\n",
       "      <td>0.285209</td>\n",
       "      <td>0.45923</td>\n",
       "      <td>0.528883</td>\n",
       "      <td>0.272435</td>\n",
       "      <td>68.443</td>\n",
       "      <td>75.358</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.51015</td>\n",
       "      <td>0.272875</td>\n",
       "      <td>methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codellama-7b_tokens_output</th>\n",
       "      <td>0.054881</td>\n",
       "      <td>0.20547</td>\n",
       "      <td>0.119731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.001</td>\n",
       "      <td>69.27</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.345021</td>\n",
       "      <td>0.067985</td>\n",
       "      <td>tokens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   average_ngram_match_score  \\\n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                  0.338706   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                  0.226282   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                  0.041936   \n",
       "base_modules                                                             NaN   \n",
       "codellama-7b_lines_output                                           0.398411   \n",
       "codellama-7b_methods_output                                         0.285209   \n",
       "codellama-7b_tokens_output                                          0.054881   \n",
       "\n",
       "                                                   average_weighted_ngram_match_score  \\\n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                           0.607381   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                           0.490709   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                           0.197008   \n",
       "base_modules                                                                      NaN   \n",
       "codellama-7b_lines_output                                                    0.578653   \n",
       "codellama-7b_methods_output                                                   0.45923   \n",
       "codellama-7b_tokens_output                                                    0.20547   \n",
       "\n",
       "                                                   average_syntax_match_score  \\\n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                   0.659051   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                   0.524821   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                   0.125959   \n",
       "base_modules                                                              NaN   \n",
       "codellama-7b_lines_output                                            0.666216   \n",
       "codellama-7b_methods_output                                          0.528883   \n",
       "codellama-7b_tokens_output                                           0.119731   \n",
       "\n",
       "                                                   average_dataflow_match_score  \\\n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                     0.316521   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                     0.315732   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                          0.0   \n",
       "base_modules                                                                NaN   \n",
       "codellama-7b_lines_output                                              0.298311   \n",
       "codellama-7b_methods_output                                            0.272435   \n",
       "codellama-7b_tokens_output                                                  0.0   \n",
       "\n",
       "                                                   average_label_token_count  \\\n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                    12.138   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                    68.443   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                     2.001   \n",
       "base_modules                                                             NaN   \n",
       "codellama-7b_lines_output                                             12.138   \n",
       "codellama-7b_methods_output                                           68.443   \n",
       "codellama-7b_tokens_output                                             2.001   \n",
       "\n",
       "                                                   average_completion_token_count  \\\n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                         72.379   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                        103.227   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                         79.894   \n",
       "base_modules                                                                  NaN   \n",
       "codellama-7b_lines_output                                                  48.021   \n",
       "codellama-7b_methods_output                                                75.358   \n",
       "codellama-7b_tokens_output                                                  69.27   \n",
       "\n",
       "                                                   successful_build_rate  \\\n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                  0.34   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                 0.341   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                 0.494   \n",
       "base_modules                                                    0.970588   \n",
       "codellama-7b_lines_output                                          0.308   \n",
       "codellama-7b_methods_output                                        0.309   \n",
       "codellama-7b_tokens_output                                         0.493   \n",
       "\n",
       "                                                   successful_build_rate_moe  \\\n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                  0.000939   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                   0.00094   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                  0.000991   \n",
       "base_modules                                                        0.001285   \n",
       "codellama-7b_lines_output                                           0.000915   \n",
       "codellama-7b_methods_output                                         0.000916   \n",
       "codellama-7b_tokens_output                                          0.000991   \n",
       "\n",
       "                                                   no_error_rate  \\\n",
       "20231202_lines_codellama-7b-lora-20231107-20163...         0.335   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...         0.338   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...         0.494   \n",
       "base_modules                                            0.970588   \n",
       "codellama-7b_lines_output                                  0.304   \n",
       "codellama-7b_methods_output                                0.305   \n",
       "codellama-7b_tokens_output                                 0.493   \n",
       "\n",
       "                                                   no_error_rate_moe  \\\n",
       "20231202_lines_codellama-7b-lora-20231107-20163...          0.000936   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...          0.000938   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...          0.000991   \n",
       "base_modules                                                0.001285   \n",
       "codellama-7b_lines_output                                   0.000912   \n",
       "codellama-7b_methods_output                                 0.000913   \n",
       "codellama-7b_tokens_output                                  0.000991   \n",
       "\n",
       "                                                   pass_at_1_rate  \\\n",
       "20231202_lines_codellama-7b-lora-20231107-20163...           0.33   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...          0.331   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...          0.494   \n",
       "base_modules                                             0.970588   \n",
       "codellama-7b_lines_output                                   0.295   \n",
       "codellama-7b_methods_output                                 0.299   \n",
       "codellama-7b_tokens_output                                  0.493   \n",
       "\n",
       "                                                   pass_at_1_rate_moe  \\\n",
       "20231202_lines_codellama-7b-lora-20231107-20163...           0.000932   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...           0.000933   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...           0.000991   \n",
       "base_modules                                                 0.001285   \n",
       "codellama-7b_lines_output                                    0.000904   \n",
       "codellama-7b_methods_output                                  0.000908   \n",
       "codellama-7b_tokens_output                                   0.000991   \n",
       "\n",
       "                                                   average_code_bleu  \\\n",
       "20231202_lines_codellama-7b-lora-20231107-20163...          0.638087   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...          0.505914   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...          0.341226   \n",
       "base_modules                                                     1.0   \n",
       "codellama-7b_lines_output                                   0.648531   \n",
       "codellama-7b_methods_output                                  0.51015   \n",
       "codellama-7b_tokens_output                                  0.345021   \n",
       "\n",
       "                                                   average_code_bleu_moe  \\\n",
       "20231202_lines_codellama-7b-lora-20231107-20163...              0.238234   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...              0.245222   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...              0.069991   \n",
       "base_modules                                                         0.0   \n",
       "codellama-7b_lines_output                                       0.249855   \n",
       "codellama-7b_methods_output                                     0.272875   \n",
       "codellama-7b_tokens_output                                      0.067985   \n",
       "\n",
       "                                                   prompt_type  \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...       lines  \n",
       "20231202_methods_codellama-7b-lora-20231107-201...     methods  \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...      tokens  \n",
       "base_modules                                               NaN  \n",
       "codellama-7b_lines_output                                lines  \n",
       "codellama-7b_methods_output                            methods  \n",
       "codellama-7b_tokens_output                              tokens  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict = {}\n",
    "evaluated_responses_directory ='../data/run_20231127_170530/evaluated_responses/'\n",
    "base_module_results_path = os.path.join(evaluated_responses_directory, 'base_module_build_results_237c7f40.json')\n",
    "logger.info(base_module_results_path)\n",
    "modules_results_df = pd.read_json(base_module_results_path).transpose()\n",
    "modules_results_df['pass'] = modules_results_df['pass'].apply(lambda x: 0 if x else 1)\n",
    "results_dict['base_modules'] = analyze_results_file(modules_results_df, True)\n",
    "\n",
    "output_files = [\n",
    "    'codellama-7b_tokens_output.csv', \n",
    "    'codellama-7b_lines_output.csv',  \n",
    "    'codellama-7b_methods_output.csv', \n",
    "    '20231202_lines_codellama-7b-lora-20231107-201630_output.csv', \n",
    "    '20231202_methods_codellama-7b-lora-20231107-201630_output.csv', \n",
    "    '20231202_tokens_codellama-7b-lora-20231107-201630_output.csv'\n",
    "    ]\n",
    "\n",
    "for file in output_files:\n",
    "    logger.info(file)\n",
    "    results_file = os.path.join(evaluated_responses_directory, file)\n",
    "    results_df = pd.read_csv(results_file)\n",
    "    model = file.replace('.csv', '')\n",
    "    results_dict[model] = analyze_results_file(results_df)\n",
    "\n",
    "    if 'lines' in model:\n",
    "        results_dict[model]['prompt_type'] = 'lines' \n",
    "    elif 'tokens' in model:\n",
    "        results_dict[model]['prompt_type'] = 'tokens' \n",
    "    elif 'methods' in model:\n",
    "        results_dict[model]['prompt_type'] = 'methods' \n",
    "\n",
    "results_df = pd.DataFrame(results_dict).transpose().sort_index()\n",
    "results_summary_path = os.path.join(evaluated_responses_directory, 'results_summary.csv')\n",
    "# results_df.to_csv(results_summary_path)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_ngram_match_score</th>\n",
       "      <th>average_weighted_ngram_match_score</th>\n",
       "      <th>average_syntax_match_score</th>\n",
       "      <th>average_dataflow_match_score</th>\n",
       "      <th>average_label_token_count</th>\n",
       "      <th>average_completion_token_count</th>\n",
       "      <th>successful_build_rate</th>\n",
       "      <th>successful_build_rate_moe</th>\n",
       "      <th>no_error_rate</th>\n",
       "      <th>no_error_rate_moe</th>\n",
       "      <th>pass_at_1_rate</th>\n",
       "      <th>pass_at_1_rate_moe</th>\n",
       "      <th>average_code_bleu</th>\n",
       "      <th>average_code_bleu_moe</th>\n",
       "      <th>prompt_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_modules</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codellama-7b_output_tokens</th>\n",
       "      <td>0.054881</td>\n",
       "      <td>0.20547</td>\n",
       "      <td>0.119731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.001</td>\n",
       "      <td>69.27</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.345021</td>\n",
       "      <td>0.067985</td>\n",
       "      <td>tokens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20231202_tokens_codellama-7b-lora-20231107-201630_output</th>\n",
       "      <td>0.041936</td>\n",
       "      <td>0.197008</td>\n",
       "      <td>0.125959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.001</td>\n",
       "      <td>79.894</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.341226</td>\n",
       "      <td>0.069991</td>\n",
       "      <td>tokens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codellama-7b_output_lines</th>\n",
       "      <td>0.398411</td>\n",
       "      <td>0.578653</td>\n",
       "      <td>0.666216</td>\n",
       "      <td>0.298311</td>\n",
       "      <td>12.138</td>\n",
       "      <td>48.021</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.648531</td>\n",
       "      <td>0.249855</td>\n",
       "      <td>lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20231202_lines_codellama-7b-lora-20231107-201630_output</th>\n",
       "      <td>0.338706</td>\n",
       "      <td>0.607381</td>\n",
       "      <td>0.659051</td>\n",
       "      <td>0.316521</td>\n",
       "      <td>12.138</td>\n",
       "      <td>72.379</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.638087</td>\n",
       "      <td>0.238234</td>\n",
       "      <td>lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codellama-7b_output_methods</th>\n",
       "      <td>0.285209</td>\n",
       "      <td>0.45923</td>\n",
       "      <td>0.528883</td>\n",
       "      <td>0.272435</td>\n",
       "      <td>68.443</td>\n",
       "      <td>75.358</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.51015</td>\n",
       "      <td>0.272875</td>\n",
       "      <td>methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20231202_methods_codellama-7b-lora-20231107-201630_output</th>\n",
       "      <td>0.226282</td>\n",
       "      <td>0.490709</td>\n",
       "      <td>0.524821</td>\n",
       "      <td>0.315732</td>\n",
       "      <td>68.443</td>\n",
       "      <td>103.227</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.00094</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.505914</td>\n",
       "      <td>0.245222</td>\n",
       "      <td>methods</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   average_ngram_match_score  \\\n",
       "base_modules                                                             NaN   \n",
       "codellama-7b_output_tokens                                          0.054881   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                  0.041936   \n",
       "codellama-7b_output_lines                                           0.398411   \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                  0.338706   \n",
       "codellama-7b_output_methods                                         0.285209   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                  0.226282   \n",
       "\n",
       "                                                   average_weighted_ngram_match_score  \\\n",
       "base_modules                                                                      NaN   \n",
       "codellama-7b_output_tokens                                                    0.20547   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                           0.197008   \n",
       "codellama-7b_output_lines                                                    0.578653   \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                           0.607381   \n",
       "codellama-7b_output_methods                                                   0.45923   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                           0.490709   \n",
       "\n",
       "                                                   average_syntax_match_score  \\\n",
       "base_modules                                                              NaN   \n",
       "codellama-7b_output_tokens                                           0.119731   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                   0.125959   \n",
       "codellama-7b_output_lines                                            0.666216   \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                   0.659051   \n",
       "codellama-7b_output_methods                                          0.528883   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                   0.524821   \n",
       "\n",
       "                                                   average_dataflow_match_score  \\\n",
       "base_modules                                                                NaN   \n",
       "codellama-7b_output_tokens                                                  0.0   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                          0.0   \n",
       "codellama-7b_output_lines                                              0.298311   \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                     0.316521   \n",
       "codellama-7b_output_methods                                            0.272435   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                     0.315732   \n",
       "\n",
       "                                                   average_label_token_count  \\\n",
       "base_modules                                                             NaN   \n",
       "codellama-7b_output_tokens                                             2.001   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                     2.001   \n",
       "codellama-7b_output_lines                                             12.138   \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                    12.138   \n",
       "codellama-7b_output_methods                                           68.443   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                    68.443   \n",
       "\n",
       "                                                   average_completion_token_count  \\\n",
       "base_modules                                                                  NaN   \n",
       "codellama-7b_output_tokens                                                  69.27   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                         79.894   \n",
       "codellama-7b_output_lines                                                  48.021   \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                         72.379   \n",
       "codellama-7b_output_methods                                                75.358   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                        103.227   \n",
       "\n",
       "                                                   successful_build_rate  \\\n",
       "base_modules                                                    0.970588   \n",
       "codellama-7b_output_tokens                                         0.493   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                 0.494   \n",
       "codellama-7b_output_lines                                          0.308   \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                  0.34   \n",
       "codellama-7b_output_methods                                        0.309   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                 0.341   \n",
       "\n",
       "                                                   successful_build_rate_moe  \\\n",
       "base_modules                                                        0.001285   \n",
       "codellama-7b_output_tokens                                          0.000991   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...                  0.000991   \n",
       "codellama-7b_output_lines                                           0.000915   \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...                  0.000939   \n",
       "codellama-7b_output_methods                                         0.000916   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...                   0.00094   \n",
       "\n",
       "                                                   no_error_rate  \\\n",
       "base_modules                                            0.970588   \n",
       "codellama-7b_output_tokens                                 0.493   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...         0.494   \n",
       "codellama-7b_output_lines                                  0.304   \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...         0.335   \n",
       "codellama-7b_output_methods                                0.305   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...         0.338   \n",
       "\n",
       "                                                   no_error_rate_moe  \\\n",
       "base_modules                                                0.001285   \n",
       "codellama-7b_output_tokens                                  0.000991   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...          0.000991   \n",
       "codellama-7b_output_lines                                   0.000912   \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...          0.000936   \n",
       "codellama-7b_output_methods                                 0.000913   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...          0.000938   \n",
       "\n",
       "                                                   pass_at_1_rate  \\\n",
       "base_modules                                             0.970588   \n",
       "codellama-7b_output_tokens                                  0.493   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...          0.494   \n",
       "codellama-7b_output_lines                                   0.295   \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...           0.33   \n",
       "codellama-7b_output_methods                                 0.299   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...          0.331   \n",
       "\n",
       "                                                   pass_at_1_rate_moe  \\\n",
       "base_modules                                                 0.001285   \n",
       "codellama-7b_output_tokens                                   0.000991   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...           0.000991   \n",
       "codellama-7b_output_lines                                    0.000904   \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...           0.000932   \n",
       "codellama-7b_output_methods                                  0.000908   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...           0.000933   \n",
       "\n",
       "                                                   average_code_bleu  \\\n",
       "base_modules                                                     1.0   \n",
       "codellama-7b_output_tokens                                  0.345021   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...          0.341226   \n",
       "codellama-7b_output_lines                                   0.648531   \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...          0.638087   \n",
       "codellama-7b_output_methods                                  0.51015   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...          0.505914   \n",
       "\n",
       "                                                   average_code_bleu_moe  \\\n",
       "base_modules                                                         0.0   \n",
       "codellama-7b_output_tokens                                      0.067985   \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...              0.069991   \n",
       "codellama-7b_output_lines                                       0.249855   \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...              0.238234   \n",
       "codellama-7b_output_methods                                     0.272875   \n",
       "20231202_methods_codellama-7b-lora-20231107-201...              0.245222   \n",
       "\n",
       "                                                   prompt_type  \n",
       "base_modules                                               NaN  \n",
       "codellama-7b_output_tokens                              tokens  \n",
       "20231202_tokens_codellama-7b-lora-20231107-2016...      tokens  \n",
       "codellama-7b_output_lines                                lines  \n",
       "20231202_lines_codellama-7b-lora-20231107-20163...       lines  \n",
       "codellama-7b_output_methods                            methods  \n",
       "20231202_methods_codellama-7b-lora-20231107-201...     methods  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.iloc[[3,6,2,4,0,5,1],:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
